{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683a90f6-4a88-40d4-8f80-2acdc1edace3",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d6b4f0-e717-48cc-a586-c5c66de8e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (0.23.4)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: trl in /opt/conda/lib/python3.11/site-packages (0.9.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from trl) (2.2.2+cu121)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.11/site-packages (from trl) (4.42.3)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.11/site-packages (from trl) (1.26.4)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (from trl) (0.31.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (from trl) (2.20.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.11/site-packages (from trl) (0.8.5)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate->trl) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (2.2.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.2.2+cu121)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.42.3)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (0.43.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (0.31.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: flash_attn in /opt/conda/lib/python3.11/site-packages (2.5.9.post1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from flash_attn) (2.2.2+cu121)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from flash_attn) (0.8.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash_attn) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->flash_attn) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->flash_attn) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.11/site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.11/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.7.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.17.2)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting de-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.11/site-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.7.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.17.2)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk) (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub sentencepiece trl\n",
    "!pip install torch transformers bitsandbytes accelerate\n",
    "!pip install flash_attn\n",
    "!pip install spacy\n",
    "!python -m spacy download de_core_news_sm\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4431b4-70e4-442a-9a2f-f0eea165420f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 18:58:22.785959: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-29 18:58:22.825989: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-29 18:58:23.581164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from transformers import pipeline\n",
    "# from trl import setup_chat_format,SFTTrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc177a33-b22d-40f9-b4b4-032b0d801605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2+cu121'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da69a2a4-ba9a-4344-a4aa-eba87208b5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/jovyan/.cache/huggingface/token\n",
      "Login successful\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Call the login function to authenticate. You'll need to enter your credentials or token.\n",
    "token = \"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\"\n",
    "login(token=token)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e962cb-1051-4a48-8863-ce6c771faabc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Model trys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19338a3d-47b1-40a8-886f-d788ec581ac0",
   "metadata": {},
   "source": [
    "We tried using Meta-Llama 8B, but it was too heavy, causing the kernel to shut down. The same issue occurred with Mistal; the model is too large.\n",
    "\n",
    "Tutorial from huggingface => https://huggingface.co/docs/transformers/llm_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637b82b-7310-48b1-972e-d3c5515a3e50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.1 Meta-LLama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b329061-c742-4dc5-9c18-ae972a660c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the model name\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "# # Load the tokenizer and model with token\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, token=token).to(device)\n",
    "\n",
    "# # Define the prompt\n",
    "# prompt = \"\"\"\n",
    "# Generate a Playwright script in TypeScript that does the following:\n",
    "# 1. Navigate to eBay Kleinanzeigen\n",
    "# 2. Accept cookies\n",
    "# 3. Accept the GDPR banner\n",
    "# 4. Search for a phone\n",
    "# 5. Take a screenshot of the search results\n",
    "# \"\"\"\n",
    "\n",
    "# # Tokenize the input\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# # Generate the script\n",
    "# outputs = model.generate(inputs.input_ids, max_length=500, num_return_sequences=1)\n",
    "\n",
    "# # Decode and print the generated text\n",
    "# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb23d2c7-c430-4c35-a0fd-7b76f78f9bcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.2 GPT-Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ea5c15-206e-413e-aa2a-c8c9b0013494",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-1.3B\" # Model name for GPT-1.3\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8823e729-1c6f-4f41-885b-69285f299b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  198,  8645,   378,   257, 11361,  4226,  1262,   262,  3811, 29995,\n",
      "          5888,   284,  1620, 12454,  4856,   319,  7444,    13,   220,   198,\n",
      "           464,  4226,   815,    25,   198,    16,    13, 13244, 10055,   284,\n",
      "           262,  7444, 35699,    13,   198,    17,    13, 21699, 14746,    13,\n",
      "           198,    18,    13, 11140,   329,   257,  2008,    13,   198,    19,\n",
      "            13,  7214,   257, 22032,   286,   262,  2989,  2482,    13,   198,\n",
      "           464,  2163,   815,   923,   355,  5679,    25,   198,  4299,  1332,\n",
      "            62, 11604,     7,  7700,    25,  7873,  2599,   198]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt\n",
    "prompt = \"\"\"\n",
    "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
    "The script should:\n",
    "1. Navigate to the YouTube webpage.\n",
    "2. Accept cookies.\n",
    "3. Search for a video.\n",
    "4. Take a screenshot of the search results.\n",
    "The function should start as follows:\n",
    "def test_youtube(page: Page):\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize input\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79eda90-4aaf-40de-b591-21472c6b580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "outputs = model.generate(input_ids=input_ids, \n",
    "                         pad_token_id=tokenizer.eos_token_id,  # Set pad token ID to EOS token ID\n",
    "                         attention_mask=input_ids.new_ones(input_ids.shape).to(device),  # Create attention mask\n",
    "                         max_length=500,\n",
    "                         do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95920567-1eae-4f0a-8c92-aab75968fd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
      "The script should:\n",
      "1. Navigate to the YouTube webpage.\n",
      "2. Accept cookies.\n",
      "3. Search for a video.\n",
      "4. Take a screenshot of the search results.\n",
      "The function should start as follows:\n",
      "def test_youtube(page: Page):\n",
      "    video_url = page.url\n",
      "    response = browser.get(video_url, params={'no_result' : True})\\\n",
      "    page\\\n",
      "     -> wait_for_page_to_load(video_url)\\\n",
      "     -> assert response(video_url).text\n",
      "\n",
      "I have a problem with the wait_for_page_to_load in the first line (line \\), because I always create the page before performing the test and the page isn't always available. I have tried to put it inside \\ if it was always available: but it is not.\n",
      "So, I need to wait for the video to appear, but I can't wait for the page to be ready. Can you please help me?\n",
      "\n",
      "A:\n",
      "\n",
      "The correct wait\\_for_page_to_load function to use is one you wrote (without the () on line \\).\n",
      "\n",
      "wait_for_page_to_load(page) - waits until page will be updated with status True or False. This is an absolute requirement.\n",
      "\n",
      "import requests\n",
      "from playwright.tools import wait_until, create_page as pagecreate\n",
      "wait_until(page.open)\n",
      "page.open = True\n",
      "\n",
      "However, because you don't specify if there is content waiting to be displayed or not, that will still be true regardless of the fact that a page is found\n",
      "\n",
      "A:\n",
      "\n",
      "Your code needs to wait until it can find the Youtube page at the URL you give.  If you only give it a string, it will still attempt to find it but will fail.\n",
      "For example, the following will not find your page:\n",
      "try:\n",
      "    response = browser.get(r'https://www.youtube.com/watch?v=CiOq_ZsXwEo')\n",
      "except urlopen:\n",
      "    continue\n",
      "\n",
      "Instead you have to give it a list of the pages\n"
     ]
    }
   ],
   "source": [
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c1fd4-1bbb-4143-bdd4-d9e06ce58a0e",
   "metadata": {},
   "source": [
    "It do something, but i dont think it can the code, seems wrong. But with finetuning the model ca do better. Also a lot of text and not so much code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d2a7e-05d4-40e6-9358-b0830bfef923",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.3 CodeT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75192e08-3dc9-421d-aa1b-2305a6c739a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a769a6f4-0a2f-4a15-9cb5-6097534f3689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test yourscreenshot for you\"_test_youtube\" : function ( )] ; #YouTube app}page.onclick (Page: Page:) {0 ] }'_test_youtube' : \"\"\"Test a YouTubetest_youtube(. test_youtube }\n"
     ]
    }
   ],
   "source": [
    "# Define the input text with the updated prompt\n",
    "text = \"\"\"\n",
    "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
    "The script should:\n",
    "1. Navigate to the YouTube webpage.\n",
    "2. Accept cookies.\n",
    "3. Search for a video.\n",
    "4. Take a screenshot of the search results.\n",
    "The function should start as follows:\n",
    "def test_youtube(page: Page):\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "input_ids = inputs.input_ids\n",
    "attention_mask = inputs.attention_mask\n",
    "\n",
    "# Generate the Python script\n",
    "generated_ids = model.generate(input_ids = input_ids,\n",
    "                               attention_mask = attention_mask,\n",
    "                               max_length=500,\n",
    "                               do_sample=True)  # Adjust max_length as needed\n",
    "generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated Python script\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a5f41-435e-4899-9164-64ba243ba8f5",
   "metadata": {},
   "source": [
    "Like in gpt. To model do something, but the model it is not fitted do this, it can do better. Sometimes to model predict random stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fc8cd-317e-4ba4-ba11-3b47d3aac8d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.4 Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d1750-4cc0-47d3-b0a3-0f35ec32b513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef339deca9fb4359bbc2e391d6787d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8ebb5d7b1941b880ab42f86a3e5d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:  25%|##4       | 1.13G/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411bfa7996234c54ba72ec26cbd9f303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.3\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ee911-ec57-4b21-8504-8a957933581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4fe28-5df1-4d7c-a67a-507472ca1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input text with the updated prompt\n",
    "text = \"\"\"\n",
    "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
    "The script should:\n",
    "1. Navigate to the YouTube webpage.\n",
    "2. Accept cookies.\n",
    "3. Search for a video.\n",
    "4. Take a screenshot of the search results.\n",
    "The function should start as follows:\n",
    "def test_youtube(page: Page):\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "# input_ids = inputs.input_ids\n",
    "# attention_mask = inputs.attention_mask\n",
    "\n",
    "# # Generate the Python script\n",
    "# generated_ids = model.generate(input_ids = input_ids,\n",
    "#                                attention_mask = attention_mask,\n",
    "#                                max_length=500,\n",
    "#                                do_sample=True)  # Adjust max_length as needed\n",
    "# generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# # Print the generated Python script\n",
    "# print(generated_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a68a1-7d1b-4741-9b89-d6a3914f56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b823c7f-c5a6-4b0a-ab31-d8ad49d79c78",
   "metadata": {},
   "source": [
    "# 2. Multimodal Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c5e86-98b5-4624-a1e1-71b92186770c",
   "metadata": {},
   "source": [
    "## 2.1 Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8902d5-2b0b-4faf-a4b9-0fad1ad96703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, Comment, NavigableString\n",
    "from PIL import Image\n",
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration, BitsAndBytesConfig\n",
    "import torch\n",
    "import spacy\n",
    "import IPython\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc8124-8cb4-4b65-a52a-4f67ffa55a3f",
   "metadata": {},
   "source": [
    "## 2.2 Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6ab84629-2246-4e36-acb8-d65d73c141bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_html_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1e937eb0-338e-4ea9-a13f-11c47e12fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "def reduce_html_spacy(html_content, description, verbosen=False):\n",
    "    \"\"\"\n",
    "    Extracts keywords from the description, searches the HTML content for these keywords, \n",
    "    and returns the simplified HTML containing the relevant sections.\n",
    "    \n",
    "    Args:\n",
    "    html_content (str): The HTML content of the webpage.\n",
    "    description (str): The task description.\n",
    "    \n",
    "    Returns:\n",
    "    str: The simplified HTML containing the relevant sections.\n",
    "    \"\"\"\n",
    "    # Extract keywords from the description\n",
    "    doc = nlp(description)\n",
    "    keywords = [token.text.lower() for token in doc if token.pos_ not in {'VERB', 'ADP', 'PUNCT', 'NUM', 'SYM', 'X', 'DET'} and not token.is_punct]\n",
    "    keywords = [keyword.strip() for keyword in keywords if keyword.strip() != ''] # Filter empty and whitespace keywords\n",
    "    if verbosen:\n",
    "        print(f'The keywords are: {keywords}')\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Function to find elements containing specific text within specific tags and attributes\n",
    "    def find_elements_by_text_and_attributes(soup, tags, attributes, text):\n",
    "        found_elements = []\n",
    "        \n",
    "        # Find elements by tags and attributes\n",
    "        for tag in tags:\n",
    "            for attribute in attributes:\n",
    "                elements = soup.find_all(tag, attrs={attribute: True}, text=lambda t: t and text in t.lower())\n",
    "                found_elements.extend(elements)\n",
    "        \n",
    "        return found_elements\n",
    "\n",
    "    # Tags and attributes to search within\n",
    "    tags_to_search = ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'button', 'a', 'li']\n",
    "    attributes_to_search = ['class', 'id']\n",
    "\n",
    "    # Dictionary to hold found elements\n",
    "    found_elements = {}\n",
    "\n",
    "    for keyword in keywords:\n",
    "        found_elements[keyword] = find_elements_by_text_and_attributes(soup, tags_to_search, attributes_to_search, keyword)\n",
    "\n",
    "    # Collect extracted HTML sections\n",
    "    extracted_html_sections = []\n",
    "\n",
    "    for keyword, elements in found_elements.items():\n",
    "        if elements:\n",
    "            for element in elements:\n",
    "                if isinstance(element, NavigableString):\n",
    "                    # Handle NavigableString separately (if needed)\n",
    "                    extracted_html = str(element)  # Convert to string or process accordingly\n",
    "                else:\n",
    "                    extracted_html = element.prettify()  # Get the prettified HTML of the element\n",
    "                extracted_html_sections.append(extracted_html)\n",
    "        else:\n",
    "            if verbosen:\n",
    "                print(f\"No elements found for keyword '{keyword}'\")\n",
    "\n",
    "    # Combine all extracted sections into one HTML string\n",
    "    simplified_html = \"\\n\".join(extracted_html_sections)\n",
    "    \n",
    "    return simplified_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "488f0ac8-7835-41de-942b-4430844b2bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    # Open the image file\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Resize image to target size\n",
    "    image = image.resize(target_size, resample=Image.LANCZOS)\n",
    "    \n",
    "    # Normalize image (assuming normalization to [0, 1] range)\n",
    "    image = np.array(image)\n",
    "    image = image / 255.0\n",
    "    \n",
    "    # Convert numpy array back to PIL Image\n",
    "    image = Image.fromarray((image * 255).astype(np.uint8))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5f301767-3e79-4fb3-ad9f-0e5f07cf6202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_previous_test_item(target_item):\n",
    "    steps = target_item[1] \n",
    "    previous_item = None\n",
    "    for item in items:\n",
    "        steps_to_compare = item[1]\n",
    "        longest_steps_to_compare_length = 0\n",
    "        if steps_to_compare in steps and not steps_to_compare == steps and len(steps_to_compare) > longest_steps_to_compare_length:\n",
    "            longest_steps_to_compare_length = len (steps_to_compare)\n",
    "            previous_item = item\n",
    "    return previous_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cb9bf395-f5de-4581-b803-38342054f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content_for_database_item(item):\n",
    "    random_item = item\n",
    "    steps = random_item[1]\n",
    "    expected_result = random_item[2]\n",
    "    \n",
    "    html_file_path = './data'+ random_item[3].replace('\\\\', '/')[1:]\n",
    "    html_content = load_html_file(html_file_path)\n",
    "    \n",
    "    image_path = './data'+random_item[4].replace('\\\\', '/')[1:]\n",
    "    image = preprocess_image(image_path)\n",
    "    \n",
    "    test_script_path = './data'+random_item[5].replace('\\\\', '/')[1:]\n",
    "    test_script = open(test_script_path, 'r', encoding='utf-8').read()\n",
    "\n",
    "    return steps, expected_result, html_content, image, test_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e5027b1d-6614-4bff-98ae-f2e5e65666ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the previous state: if no previous test/step for the current step exists, step_0 is used as previous test & context\n",
    "def extract_content_for_previous_database_item(target):\n",
    "    previous = find_previous_test_item(target)\n",
    "    if previous != None:\n",
    "        steps_p, expected_result_p, html_content_p, image_p, test_script_p = extract_content_for_database_item(previous)\n",
    "    else:\n",
    "        steps_p = \"\" \n",
    "        expected_result_p = \"\"\n",
    "        html_content_p = load_html_file('data/html/0_1.html')\n",
    "        image_p = Image.open('data/screenshot/0_1.png')\n",
    "        test_script_p = open('data/test_script/0_1.spec.ts', 'r', encoding='utf-8').read()\n",
    "\n",
    "    return steps_p, expected_result_p, html_content_p, image_p, test_script_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5ee413e9-d784-4e4e-a5db-152b611656bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_step(target, verbosen=False):\n",
    "    search_text = '[' + target[0] +']'\n",
    "    index_1_3 = target[1].find(search_text)\n",
    "    if index_1_3 != -1:\n",
    "        # Extract substring starting right after '[1.3]'\n",
    "        return target[1][index_1_3:].strip()\n",
    "    else:\n",
    "        if verbosen:\n",
    "            print(f'Teststep {search_text} not found in the input string.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1d3bd7e5-ec9a-412f-9953-7722f7b03752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_step_code(target):\n",
    "    steps, expected_result, html_content, image, test_script = extract_content_for_database_item(target)\n",
    "    steps_p, expected_result_p, html_content_p, image_p, test_script_p = extract_content_for_previous_database_item (target)\n",
    "\n",
    "    lines1 = test_script.splitlines()\n",
    "    lines2 = test_script_p.splitlines()\n",
    "\n",
    "    # Remove duplicate lines from script1\n",
    "    cleaned_lines = [line1 for line1 in lines1 if all(line1 != line2 for line2 in lines2)]\n",
    "\n",
    "    # Join lines back into a single string\n",
    "    cleaned_script = \"\\n\".join(cleaned_lines)\n",
    "    \n",
    "    return cleaned_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c0f63ae5-5d50-4a47-b15f-1a3a5c85c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_tests(target, n=1):\n",
    "    # find n most similar test => modifiy function of Kathi\n",
    "    # Combine current description and other descriptions for vectorization\n",
    "    last_step_of_target = get_last_step(target)\n",
    "    index_last_step = last_step_of_target.find(']') + 1\n",
    "    \n",
    "    all_descriptions = []\n",
    "    original_items = []\n",
    "    \n",
    "    for item in items:\n",
    "        last_step_of_another = get_last_step(item)\n",
    "        index_other_step = last_step_of_another.find(']') + 1\n",
    "        \n",
    "        if last_step_of_another[index_other_step:] != last_step_of_target[index_last_step:]:\n",
    "            all_descriptions.append(last_step_of_another)\n",
    "            original_items.append(item)\n",
    "    \n",
    "    all_descriptions = [last_step_of_target] + all_descriptions\n",
    "    \n",
    "    # Initialize TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_descriptions)\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
    "    \n",
    "    # Get the indices of the top 'num' most similar descriptions\n",
    "    most_similar_indices = cosine_similarities.argsort()[-n:][::-1]  # Indices of the top `num` similarities\n",
    "    \n",
    "    # Retrieve the corresponding test samples\n",
    "    most_similar_tests = [original_items[i] for i in most_similar_indices]\n",
    "    \n",
    "    return most_similar_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e4d18b17-9890-4eb6-bc56-9c7bcb367fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_python_code(answer, filename=None, save=True):\n",
    "    # Define the pattern to find the JavaScript code block\n",
    "    pattern = r'```javascript(.*?)(```|$)'  # Match until triple backticks or end of string\n",
    "    # Find all matches of the pattern in the answer\n",
    "    matches = re.findall(pattern, answer, re.DOTALL)\n",
    "    if matches:\n",
    "        # Handle that the LLM is formatting the Comments wrong, get the last match\n",
    "        match = matches[-1][0]\n",
    "        python_code = str(match.strip())\n",
    "        if save:\n",
    "            with open(filename, 'w', encoding='utf-8') as file:\n",
    "                file.write(python_code)\n",
    "        return python_code\n",
    "    else:\n",
    "        return None  # Return None if no Python code block is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "30bdff4f-85f8-4c04-b2c2-b3d8ffa2c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_code(code):\n",
    "    # Remove inline comments (anything after #)\n",
    "    code = re.sub(r'//.*', '', code)\n",
    "    \n",
    "    # Remove block comments (anything between ''' and ''', or \"\"\" and \"\"\")\n",
    "    code = re.sub(r\"'''[\\s\\S]*?'''\", '', code)\n",
    "    code = re.sub(r'\"\"\"[\\s\\S]*?\"\"\"', '', code)\n",
    "\n",
    "    # Remove new lines\n",
    "    code = re.sub(r'\\n', '', code)\n",
    "\n",
    "    return code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd2cef-0881-45b7-aa0b-c17524c1ee08",
   "metadata": {},
   "source": [
    "## 2.3 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e766c321-b7e4-4a3c-8181-742d42412ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e34594f128491d839cef3cafd46769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quantization for low memory usage\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",  # Set the quantization type to 'nf4', a specific 4-bit format\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,  # Enable 8-bit quantization\n",
    "#     llm_int8_threshold=6.0  # Optional: fine-tune the threshold\n",
    "# )\n",
    "processor = LlavaNextProcessor.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\")\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    \"llava-hf/llava-v1.6-mistral-7b-hf\", \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True,\n",
    "    #attn_implementation=\"flash_attention_2\",  # Updated deprecated parameter\n",
    "    quantization_config=quantization_config  # Pass the quantization config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b343bd18-8cf5-46fb-bb2c-d12a52923988",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.3.1 Easy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66e0e092-e402-43ad-a82b-781fdbe4f8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]  \n",
      "Please write a python code for a UI test using playwright. [/INST] Certainly! Below is a Python code snippet that uses Playwright to perform UI tests on a webpage. This code snippet assumes you have Playwright installed and configured.\n",
      "\n",
      "```python\n",
      "import asyncio\n",
      "import time\n",
      "from playwright.async_api import Playwright, async_playwright, Browser, Page\n",
      "\n",
      "async def test_cadenzapage():\n",
      "    async with async_playwright() as playwright:\n",
      "        browser = await playwright.chromium.launch()\n",
      "        page = await browser.newPage()\n",
      "\n",
      "        # Navigate to the Cadenzapage\n",
      "        await page.goto('https://www.cadenzapage.com')\n",
      "\n",
      "        # Wait for the page to load\n",
      "        await page.wait_for_selector('#disy-cadenzapage')\n",
      "\n",
      "        # Click on the Cadenzapage link\n",
      "        await page.click('#disy-cadenzapage')\n",
      "\n",
      "        # Wait for the page to change\n",
      "        await page.wait_for_selector('#disy-cadenzapage-spring-2024')\n",
      "\n",
      "        # Click on the Spring 2024 link\n",
      "        await page.click('#disy-cadenzapage-spring-2024')\n",
      "\n",
      "        # Wait for the page to change\n",
      "        await page.wait_for_selector('#disy-cadenzapage-spring-2024-dashboard')\n",
      "\n",
      "        # Click on the Dashboard link\n",
      "        await page.click('#disy-cadenzapage-spring-2024-dashboard')\n",
      "\n",
      "        # Wait for the page to change\n",
      "        await page.wait_for_selector('#disy-cadenzapage-spring-2024-dashboard-reporting')\n",
      "\n",
      "        # Click on the Reporting link\n",
      "        await page.click('#disy-cadenzapage-spring-2024-dashboard-reporting')\n",
      "\n",
      "        # Wait for the page to change\n",
      "        await page.wait_for_selector('#disy-cadenzapage-spring-2024-dashboard-reporting-location-analytics')\n",
      "\n",
      "        # Click on the Location Analytics link\n",
      "        await page.click\n"
     ]
    }
   ],
   "source": [
    "# One example with a image to see if it work\n",
    "image_path = 'data/screenshot/0_1.png'  # Replace with your image path\n",
    "image = Image.open(image_path)\n",
    "prompt = \"[INST] <image>\\nPlease write a python code for a UI test using playwright. [/INST]\"\n",
    "inputs = processor(prompt, image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# autoregressively complete prompt\n",
    "output = model.generate(**inputs, max_new_tokens=500)\n",
    "print(processor.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d377df9-34be-43e6-9f5e-1fea5dc3a04e",
   "metadata": {},
   "source": [
    "## 2.3 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed0fd74e-12d4-4017-bdc1-4d2b8a883fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 100 data.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('./data/playwright_script.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "res = cursor.execute(\"SELECT * FROM tests\")\n",
    "items = res.fetchall()\n",
    "\n",
    "print( \"there are {} data.\".format(len(items)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1718c-0747-40c0-b058-8abe17c5ec44",
   "metadata": {},
   "source": [
    "### 2.3.1 Load Login script, screenshot and HTML as step 0/initial step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea556a-411b-466f-9559-daaaa6541b91",
   "metadata": {},
   "source": [
    "When we want to genereate code for the first step of a test, we do not have context from the previous step since it is the first one. In this case we use the login as context/previous step. An image and HTML from after only the login was already provided with the test-ID 0, we further created a test script for this test 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6c37412-5323-4312-ab57-5e469ad27d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if HTML with ID 0 belongs to any existing test \n",
    "for it in items:\n",
    "    if it[3] == '.\\\\html\\\\0_1.html':\n",
    "        print(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51da1783-dac9-4873-a821-4f84d0dfa5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_0_html = load_html_file('data/html/0_1.html')\n",
    "step_0_image = preprocess_image('data/screenshot/0_1.png')\n",
    "step_0_test_script = open('data/test_script/0_1.spec.ts', 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcddf4cd-85eb-40fb-b7e8-7c616fb5ecae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "\n",
      "\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "});\n"
     ]
    }
   ],
   "source": [
    "print(step_0_test_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60af50b-35b9-4a76-bcb1-0adcf82f1455",
   "metadata": {},
   "source": [
    "#### Load one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd0ba66a-1bf5-46e0-a189-2eb7a94ab060",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = items[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96b40f33-ca62-434a-8950-5effbbfcdde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the content\n",
    "steps, expected_result, html_content, image, test_script = extract_content_for_database_item(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f4cd38f-f7f3-4f2e-8bb1-2f29344acbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: [1.1] Öffne die Arbeitsmappe \"Übersicht Messstellen\" im Ordner \"Gewässergüte\". [1.2]  Öffnen der Tabellen-Sicht \"Messstellenliste\" über die Werkzeugliste der Arbeitsmappe.\n",
      "Image format: None\n",
      "Image size: (224, 224)\n",
      "Image mode: RGB\n"
     ]
    }
   ],
   "source": [
    "# Display information about the image\n",
    "print(f\"Steps: {steps}\")\n",
    "print(f\"Image format: {image.format}\")\n",
    "print(f\"Image size: {image.size}\")\n",
    "print(f\"Image mode: {image.mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40cddb1f-11b3-4e6d-bc4a-2256db60d100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last step of test sample:\n",
      "[1.2]  Öffnen der Tabellen-Sicht \"Messstellenliste\" über die Werkzeugliste der Arbeitsmappe.\n"
     ]
    }
   ],
   "source": [
    "last_step = get_last_step(target, verbosen=True)\n",
    "print(\"Last step of test sample:\")\n",
    "print(last_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d67ec847-b9fe-40ec-9e1f-b49fa057e94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code to implement the last step:\n",
      "  await page.getByRole('link', { name: 'Tabelle Messstellenliste' }).click();\n"
     ]
    }
   ],
   "source": [
    "print(\"Code to implement the last step:\")\n",
    "print(get_last_step_code(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dca650-eda7-4f88-a0cf-d7454f370114",
   "metadata": {},
   "source": [
    "#### Find previous test test to current one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afc6f7dc-04dc-48b2-a2cd-5fbac5e217db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: [1.1] Öffne die Arbeitsmappe \"Übersicht Messstellen\" im Ordner \"Gewässergüte\".\n",
      "\n",
      "Script: import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "\n",
      "\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByText('Verzeichnis Gewässergüte', { exact: true }).click();\n",
      "  const parentElement = await page.getByText('Arbeitsmappe Übersicht Messstellen').locator('..');\n",
      "  await parentElement.locator('.d-icon.d-icon-bold.status-icon').click(); \n",
      "\n",
      "});\n"
     ]
    }
   ],
   "source": [
    "# get info from previous test \n",
    "steps_p, expected_result_p, html_content_p, image_p, test_script_p = extract_content_for_previous_database_item(target)\n",
    "print(f\"Steps: {steps_p}\")\n",
    "print()\n",
    "print(f\"Script: {test_script_p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7735220-59b1-462e-acd8-63b0a145720f",
   "metadata": {},
   "source": [
    "#### Find most similar test to current one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae6b1bd3-34a9-41e9-8d77-45c748e9dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One most similar item\n",
    "most_similar = find_most_similar_tests(target)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d456bc63-8f14-4d49-a73b-3d307b9480c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_example, expected_result_example, html_content_example, image_example, test_script_example = extract_content_for_database_item(most_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fa91c50-74e9-40f9-950a-1fa0ae92daac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[30.2] Öffne die Karten-Sicht \"Messstellenkarte\" über die Werkzeugliste der Arbeitsmappe.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find most similar test step in the test data base to provide it as example\n",
    "most_similar_step = get_last_step(most_similar, verbosen=True)\n",
    "most_similar_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4f741c8-b1fe-40a6-8bc5-a35418c8b6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  const page1Promise = page.waitForEvent('popup');\n",
      "  await page.getByRole('link', { name: 'Messstellenkarte' }).click();\n",
      "  const page1 = await page1Promise;\n"
     ]
    }
   ],
   "source": [
    "# Code to implement the most similar test step \n",
    "most_similar_code = (get_last_step_code(most_similar))\n",
    "print(most_similar_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6aaa23a-f1e5-44f1-9fce-49048fbb46a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByText('Verzeichnis Gewässergüte', { exact: true }).click();\n",
      "  await page.getByRole('link', { name: 'Übersicht Messstellen' }).click();\n",
      "});\n"
     ]
    }
   ],
   "source": [
    "# hole script of the most similar test\n",
    "_, _, _, _, test_script_example_p = extract_content_for_previous_database_item (most_similar)\n",
    "print(test_script_example_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a3c330-b0a2-43c1-aee7-dfe0cf33ece4",
   "metadata": {},
   "source": [
    "## 2.4 Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fc888915-5877-437b-8919-eef026fe1a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "[INST] \n",
    "Schreiben Sie den Playwright-Code, um den folgenden Schritt eines UI-Tests auf der Cadenza-Website zu implementieren: {last_step}.\n",
    "Verwenden Sie die folgenden Ressourcen, um den Code zu erstellen:\n",
    "1. Skript der vorherigen Schritte: {test_script_p}\n",
    "2. HTML-Datei nach den vorherigen Schritten: {html_reduce_p}\n",
    "3. Screenshot nach den vorherigen Schritten: <image>\n",
    "Schreiben Sie ausschließlich den Code für die Implementierung des nächsten gegebenen Schrittes.\n",
    "[/INST]'''\n",
    "prompt_output = '''\n",
    "```javascript\n",
    "{test_script}\n",
    "```'''\n",
    "target = items[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05754f3-11ac-4821-a6b1-da9665e172ad",
   "metadata": {},
   "source": [
    "### 2.4.1 Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "22ac9f91-c4bc-45dc-b24a-e829a8da7f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] \n",
      "Schreiben Sie den Playwright-Code, um den folgenden Schritt eines UI-Tests auf der Cadenza-Website zu implementieren: [2.2]  wähle Repository \"Gewaesser\"..\n",
      "Verwenden Sie die folgenden Ressourcen, um den Code zu erstellen:\n",
      "1. Skript der vorherigen Schritte: import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByTestId('create-workbook-button').click();\n",
      "\n",
      "});\n",
      "2. HTML-Datei nach den vorherigen Schritten: \n",
      "3. Screenshot nach den vorherigen Schritten: <image>\n",
      "Schreiben Sie ausschließlich den Code für die Implementierung des nächsten gegebenen Schrittes.\n",
      "[/INST]\n",
      "------------------------------\n",
      "Length of prompt in char is: 1046\n",
      "HTML reduce from 53441 to 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10351/2920275253.py:31: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  elements = soup.find_all(tag, attrs={attribute: True}, text=lambda t: t and text in t.lower())\n"
     ]
    }
   ],
   "source": [
    "steps, expected_result, html_content, image, test_script = extract_content_for_database_item(target)\n",
    "steps_p, expected_result_p, html_content_p, image_p, test_script_p = extract_content_for_previous_database_item(target)\n",
    "last_step = get_last_step(target)\n",
    "html_reduce_p = reduce_html_spacy(html_content_p, last_step)\n",
    "prompt_zero_shot = prompt_filled = prompt_template.format(\n",
    "                                last_step=last_step,\n",
    "                                test_script_p=test_script_p,\n",
    "                                html_reduce_p=html_reduce_p,\n",
    "                                )\n",
    "image_zero_shot = image\n",
    "prompt_zero_shot\n",
    "\n",
    "print(prompt_zero_shot)\n",
    "print(\"-\"*30)\n",
    "print(f\"Length of prompt in char is: {len(prompt_zero_shot)}\")\n",
    "print(f\"HTML reduce from {len(html_content_p)} to {len(html_reduce_p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aad35795-412f-4394-a607-9ac434ccba05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(prompt_zero_shot, image_zero_shot, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(**inputs, max_new_tokens=500)\n",
    "generated_zero_shot = processor.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44093a3b-f536-4dc9-b567-4d91d7c6d828",
   "metadata": {},
   "source": [
    "### 2.4.2 One-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a7fafb4-69b9-4a2a-9be8-41b3897a3b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] \n",
      "Schreiben Sie den Playwright-Code, um den folgenden Schritt eines UI-Tests auf der Cadenza-Website zu implementieren: [30.2] Öffne die Karten-Sicht \"Messstellenkarte\" über die Werkzeugliste der Arbeitsmappe..\n",
      "Verwenden Sie die folgenden Ressourcen, um den Code zu erstellen:\n",
      "1. Skript der vorherigen Schritte: import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByText('Verzeichnis Gewässergüte', { exact: true }).click();\n",
      "  await page.getByRole('link', { name: 'Übersicht Messstellen' }).click();\n",
      "});\n",
      "2. HTML-Datei nach den vorherigen Schritten: <button aria-haspopup=\"menu\" class=\"button button-with-dropdown button-borderless worksheet-navigation\" type=\"button\">\n",
      " <span class=\"worksheet-navigation--worksheet-name ellipsis\">\n",
      "  Informationen zur Arbeitsmappe\n",
      " </span>\n",
      "</button>\n",
      "\n",
      "3. Screenshot nach den vorherigen Schritten: <image>\n",
      "Schreiben Sie ausschließlich den Code für die Implementierung des nächsten gegebenen Schrittes.\n",
      "[/INST]\n",
      "\n",
      "```javascript\n",
      "import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByText('Verzeichnis Gewässergüte', { exact: true }).click();\n",
      "  await page.getByRole('link', { name: 'Übersicht Messstellen' }).click();\n",
      "  const page1Promise = page.waitForEvent('popup');\n",
      "  await page.getByRole('link', { name: 'Messstellenkarte' }).click();\n",
      "  const page1 = await page1Promise;\n",
      "});\n",
      "```\n",
      "\n",
      "[INST] \n",
      "Schreiben Sie den Playwright-Code, um den folgenden Schritt eines UI-Tests auf der Cadenza-Website zu implementieren: [1.2]  Öffnen der Tabellen-Sicht \"Messstellenliste\" über die Werkzeugliste der Arbeitsmappe..\n",
      "Verwenden Sie die folgenden Ressourcen, um den Code zu erstellen:\n",
      "1. Skript der vorherigen Schritte: import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "\n",
      "\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByText('Verzeichnis Gewässergüte', { exact: true }).click();\n",
      "  const parentElement = await page.getByText('Arbeitsmappe Übersicht Messstellen').locator('..');\n",
      "  await parentElement.locator('.d-icon.d-icon-bold.status-icon').click(); \n",
      "\n",
      "});\n",
      "2. HTML-Datei nach den vorherigen Schritten: <p class=\"section-text-with-symbols--item\">\n",
      " <span>\n",
      "  Die Startseite von disy Cadenza ist zweigeteilt. Auf der linken Seite sehen Sie den sogenannten Navigator, über den Sie auf die angebundenen Daten zugreifen und diese visualisieren können. Auf der Startseite ist er immer geöffnet. Sobald Sie eine Arbeitsmappe oder eine Einzelsicht öffnen, wird der Navigator automatisch geschlossen.\n",
      " </span>\n",
      "</p>\n",
      "\n",
      "<p class=\"symbol-navigator section-text-with-symbols--item\">\n",
      " <span>\n",
      "  Sie können den Navigator jederzeit wieder öffnen, indem Sie in der Hauptleiste auf die Schaltfläche „Navigator“ klicken.\n",
      " </span>\n",
      "</p>\n",
      "\n",
      "<p class=\"section-text-with-symbols--item\">\n",
      " <span>\n",
      "  Die Startseite von disy Cadenza ist zweigeteilt. Auf der linken Seite sehen Sie den sogenannten Navigator, über den Sie auf die angebundenen Daten zugreifen und diese visualisieren können. Auf der Startseite ist er immer geöffnet. Sobald Sie eine Arbeitsmappe oder eine Einzelsicht öffnen, wird der Navigator automatisch geschlossen.\n",
      " </span>\n",
      "</p>\n",
      "\n",
      "<p class=\"symbol-workbook section-text-with-symbols--item\">\n",
      " <span>\n",
      "  Klicken Sie auf dieses Symbol, um eine neue, leere Arbeitsmappe zu erstellen.\n",
      " </span>\n",
      "</p>\n",
      "\n",
      "<h2 class=\"flag\">\n",
      " 4 Arbeitsmappen\n",
      "</h2>\n",
      "\n",
      "3. Screenshot nach den vorherigen Schritten: <image>\n",
      "Schreiben Sie ausschließlich den Code für die Implementierung des nächsten gegebenen Schrittes.\n",
      "[/INST]\n",
      "------------------------------\n",
      "Length of prompt in char is: 4780\n",
      "HTML reduce from 65070 to 1217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10351/2920275253.py:31: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  elements = soup.find_all(tag, attrs={attribute: True}, text=lambda t: t and text in t.lower())\n"
     ]
    }
   ],
   "source": [
    "shots=1\n",
    "prompt = ''\n",
    "img = []\n",
    "\n",
    "most_similar_tests = find_most_similar_tests(target, n=shots)\n",
    "for example in most_similar_tests:\n",
    "    steps_e, expected_result_e, html_content_e, image_e, test_script_e = extract_content_for_database_item(example)\n",
    "    steps_p_e, expected_result_p_e, html_content_p_e, image_p_e, test_script_p_e = extract_content_for_previous_database_item(example)\n",
    "    last_step_e = get_last_step(example)\n",
    "    html_reduce_p_e = reduce_html_spacy(html_content_p_e, last_step_e)\n",
    "    prompt_filled = prompt_template.format(\n",
    "                    last_step=last_step_e,\n",
    "                    test_script_p=test_script_p_e,\n",
    "                    html_reduce_p=html_reduce_p_e,\n",
    "                    )\n",
    "    prompt_filled_output = prompt_output.format(\n",
    "                    test_script=test_script_e,\n",
    "                    )\n",
    "    prompt += prompt_filled + \"\\n\" + prompt_filled_output + \"\\n\"\n",
    "    img.append(image_p_e)\n",
    "\n",
    "prompt += prompt_zero_shot\n",
    "img.append(image)\n",
    "prompt_one_shot = prompt\n",
    "img_one_shot = img\n",
    "\n",
    "print(prompt_one_shot)\n",
    "print(\"-\"*30)\n",
    "print(f\"Length of prompt in char is: {len(prompt_one_shot)}\")\n",
    "print(f\"HTML reduce from {len(html_content_p)} to {len(html_reduce_p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bb38d2a-95ab-4528-b2e0-802c83500e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(prompt_one_shot, img_one_shot, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(**inputs, max_new_tokens=500)\n",
    "generated_one_shot = processor.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320e9af-689a-439d-a1ee-3051d3f41c1a",
   "metadata": {},
   "source": [
    "### 2.4.3 Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "086971e6-37d0-45ab-a554-1b462b65b156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] \n",
      "Schreiben Sie den Playwright-Code, um den folgenden Schritt eines UI-Tests auf der Cadenza-Website zu implementieren: [30.2] Öffne die Karten-Sicht \"Messstellenkarte\" über die Werkzeugliste der Arbeitsmappe..\n",
      "Verwenden Sie die folgenden Ressourcen, um den Code zu erstellen:\n",
      "1. Skript der vorherigen Schritte: import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByText('Verzeichnis Gewässergüte', { exact: true }).click();\n",
      "  await page.getByRole('link', { name: 'Übersicht Messstellen' }).click();\n",
      "});\n",
      "2. HTML-Datei nach den vorherigen Schritten: <button aria-haspopup=\"menu\" class=\"button button-with-dropdown button-borderless worksheet-navigation\" type=\"button\">\n",
      " <span class=\"worksheet-navigation--worksheet-name ellipsis\">\n",
      "  Informationen zur Arbeitsmappe\n",
      " </span>\n",
      "</button>\n",
      "\n",
      "3. Screenshot nach den vorherigen Schritten: <image>\n",
      "Schreiben Sie ausschließlich den Code für die Implementierung des nächsten gegebenen Schrittes.\n",
      "[/INST]\n",
      "\n",
      "```javascript\n",
      "import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByText('Verzeichnis Gewässergüte', { exact: true }).click();\n",
      "  await page.getByRole('link', { name: 'Übersicht Messstellen' }).click();\n",
      "  const page1Promise = page.waitForEvent('popup');\n",
      "  await page.getByRole('link', { name: 'Messstellenkarte' }).click();\n",
      "  const page1 = await page1Promise;\n",
      "});\n",
      "```\n",
      "\n",
      "[INST] \n",
      "Schreiben Sie den Playwright-Code, um den folgenden Schritt eines UI-Tests auf der Cadenza-Website zu implementieren: [26.2] Öffnen den Link \"Messstellenliste\".\n",
      "Verwenden Sie die folgenden Ressourcen, um den Code zu erstellen:\n",
      "1. Skript der vorherigen Schritte: import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByText('Verzeichnis Gewässergüte', { exact: true }).click();\n",
      "  const parentElement = await page.getByText('Arbeitsmappe Übersicht Messstellen').locator('..');\n",
      "  await parentElement.locator('.d-icon.d-icon-bold.status-icon').click(); \n",
      "});\n",
      "2. HTML-Datei nach den vorherigen Schritten: <p class=\"section-text-with-symbols--item\">\n",
      " <span>\n",
      "  Die Startseite von disy Cadenza ist zweigeteilt. Auf der linken Seite sehen Sie den sogenannten Navigator, über den Sie auf die angebundenen Daten zugreifen und diese visualisieren können. Auf der Startseite ist er immer geöffnet. Sobald Sie eine Arbeitsmappe oder eine Einzelsicht öffnen, wird der Navigator automatisch geschlossen.\n",
      " </span>\n",
      "</p>\n",
      "\n",
      "<p class=\"symbol-navigator section-text-with-symbols--item\">\n",
      " <span>\n",
      "  Sie können den Navigator jederzeit wieder öffnen, indem Sie in der Hauptleiste auf die Schaltfläche „Navigator“ klicken.\n",
      " </span>\n",
      "</p>\n",
      "\n",
      "<p class=\"section-text-with-symbols--item\">\n",
      " <span>\n",
      "  Die Startseite von disy Cadenza ist zweigeteilt. Auf der linken Seite sehen Sie den sogenannten Navigator, über den Sie auf die angebundenen Daten zugreifen und diese visualisieren können. Auf der Startseite ist er immer geöffnet. Sobald Sie eine Arbeitsmappe oder eine Einzelsicht öffnen, wird der Navigator automatisch geschlossen.\n",
      " </span>\n",
      "</p>\n",
      "\n",
      "3. Screenshot nach den vorherigen Schritten: <image>\n",
      "Schreiben Sie ausschließlich den Code für die Implementierung des nächsten gegebenen Schrittes.\n",
      "[/INST]\n",
      "\n",
      "```javascript\n",
      "import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByText('Verzeichnis Gewässergüte', { exact: true }).click();\n",
      "  const parentElement = await page.getByText('Arbeitsmappe Übersicht Messstellen').locator('..');\n",
      "  await parentElement.locator('.d-icon.d-icon-bold.status-icon').click(); \n",
      "  await page.getByRole('link', { name: 'Tabelle Messstellenliste' }).click();\n",
      "});\n",
      "```\n",
      "\n",
      "[INST] \n",
      "Schreiben Sie den Playwright-Code, um den folgenden Schritt eines UI-Tests auf der Cadenza-Website zu implementieren: [1.2]  Öffnen der Tabellen-Sicht \"Messstellenliste\" über die Werkzeugliste der Arbeitsmappe..\n",
      "Verwenden Sie die folgenden Ressourcen, um den Code zu erstellen:\n",
      "1. Skript der vorherigen Schritte: import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "\n",
      "\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByText('Verzeichnis Gewässergüte', { exact: true }).click();\n",
      "  const parentElement = await page.getByText('Arbeitsmappe Übersicht Messstellen').locator('..');\n",
      "  await parentElement.locator('.d-icon.d-icon-bold.status-icon').click(); \n",
      "\n",
      "});\n",
      "2. HTML-Datei nach den vorherigen Schritten: <p class=\"section-text-with-symbols--item\">\n",
      " <span>\n",
      "  Die Startseite von disy Cadenza ist zweigeteilt. Auf der linken Seite sehen Sie den sogenannten Navigator, über den Sie auf die angebundenen Daten zugreifen und diese visualisieren können. Auf der Startseite ist er immer geöffnet. Sobald Sie eine Arbeitsmappe oder eine Einzelsicht öffnen, wird der Navigator automatisch geschlossen.\n",
      " </span>\n",
      "</p>\n",
      "\n",
      "<p class=\"symbol-navigator section-text-with-symbols--item\">\n",
      " <span>\n",
      "  Sie können den Navigator jederzeit wieder öffnen, indem Sie in der Hauptleiste auf die Schaltfläche „Navigator“ klicken.\n",
      " </span>\n",
      "</p>\n",
      "\n",
      "<p class=\"section-text-with-symbols--item\">\n",
      " <span>\n",
      "  Die Startseite von disy Cadenza ist zweigeteilt. Auf der linken Seite sehen Sie den sogenannten Navigator, über den Sie auf die angebundenen Daten zugreifen und diese visualisieren können. Auf der Startseite ist er immer geöffnet. Sobald Sie eine Arbeitsmappe oder eine Einzelsicht öffnen, wird der Navigator automatisch geschlossen.\n",
      " </span>\n",
      "</p>\n",
      "\n",
      "<p class=\"symbol-workbook section-text-with-symbols--item\">\n",
      " <span>\n",
      "  Klicken Sie auf dieses Symbol, um eine neue, leere Arbeitsmappe zu erstellen.\n",
      " </span>\n",
      "</p>\n",
      "\n",
      "<h2 class=\"flag\">\n",
      " 4 Arbeitsmappen\n",
      "</h2>\n",
      "\n",
      "3. Screenshot nach den vorherigen Schritten: <image>\n",
      "Schreiben Sie ausschließlich den Code für die Implementierung des nächsten gegebenen Schrittes.\n",
      "[/INST]\n",
      "------------------------------\n",
      "Length of prompt in char is: 7897\n",
      "HTML reduce from 65070 to 1217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10351/2920275253.py:31: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  elements = soup.find_all(tag, attrs={attribute: True}, text=lambda t: t and text in t.lower())\n"
     ]
    }
   ],
   "source": [
    "shots=2\n",
    "prompt = ''\n",
    "img = []\n",
    "\n",
    "most_similar_tests = find_most_similar_tests(target, n=shots)\n",
    "for example in most_similar_tests:\n",
    "    steps_e, expected_result_e, html_content_e, image_e, test_script_e = extract_content_for_database_item(example)\n",
    "    steps_p_e, expected_result_p_e, html_content_p_e, image_p_e, test_script_p_e = extract_content_for_previous_database_item(example)\n",
    "    last_step_e = get_last_step(example)\n",
    "    html_reduce_p_e = reduce_html_spacy(html_content_p_e, last_step_e)\n",
    "    prompt_filled = prompt_template.format(\n",
    "                    last_step=last_step_e,\n",
    "                    test_script_p=test_script_p_e,\n",
    "                    html_reduce_p=html_reduce_p_e,\n",
    "                    )\n",
    "    prompt_filled_output = prompt_output.format(\n",
    "                    test_script=test_script_e,\n",
    "                    )\n",
    "    prompt += prompt_filled + \"\\n\" + prompt_filled_output + \"\\n\"\n",
    "    img.append(image_p_e)\n",
    "\n",
    "prompt += prompt_zero_shot\n",
    "img.append(image)\n",
    "prompt_few_shot = prompt\n",
    "img_few_shot = img\n",
    "\n",
    "print(prompt_few_shot)\n",
    "print(\"-\"*30)\n",
    "print(f\"Length of prompt in char is: {len(prompt_few_shot)}\")\n",
    "print(f\"HTML reduce from {len(html_content_p)} to {len(html_reduce_p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf9eea9f-5564-4693-b7c4-b335d3d3c064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(prompt_few_shot, img_few_shot, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(**inputs, max_new_tokens=500)\n",
    "generated_few_shot = processor.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4244957d-4ecc-4d01-b41b-dc7c991a0074",
   "metadata": {},
   "source": [
    "### 2.4.3 Code comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "63d9a5fd-54c7-4fa2-8720-4dec06170613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:53:32) [GCC 12.3.0]\n",
      "Type 'copyright', 'credits' or 'license' for more information\n",
      "IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In [1]:  matches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: [(\"\\nawait page.getByRole('link', { name: 'Gewaesser' }).click();\\n\", '```')]\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In [2]:  generated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[2]: '\\n[INST] \\nSchreiben Sie den Playwright-Code, um den folgenden Schritt eines UI-Tests auf der Cadenza-Website zu implementieren: [2.2]  wähle Repository \"Gewaesser\"..\\nVerwenden Sie die folgenden Ressourcen, um den Code zu erstellen:\\n1. Skript der vorherigen Schritte: import { test, expect } from \\'@playwright/test\\';\\nimport { writeFileSync } from \\'fs\\';\\ntest(\\'test\\', async ({ page }) => {\\n  await page.goto(\\'http://localhost:8080/cadenza/\\');\\n  await page.getByRole(\\'link\\', { name: \\'Anmelden\\' }).click();\\n  await page.getByLabel(\\'Benutzername *\\').click();\\n  await page.getByLabel(\\'Benutzername *\\').fill(\\'Admin\\');\\n  await page.getByLabel(\\'Benutzername *\\').press(\\'Tab\\');\\n  await page.getByPlaceholder(\\' \\').fill(\\'Admin\\');\\n  await page.getByRole(\\'button\\', { name: \\'Anmelden\\' }).click();\\n  await page.getByTestId(\\'create-workbook-button\\').click();\\n\\n});\\n2. HTML-Datei nach den vorherigen Schritten: \\n3. Screenshot nach den vorherigen Schritten:  \\nSchreiben Sie ausschließlich den Code für die Implementierung des nächsten gegebenen Schrittes.\\n[/INST]\\n```javascript\\ntest(\\'test\\', async ({ page }) => {\\n  await page.goto(\\'http://localhost:8080/cadenza/\\');\\n  await page.getByRole(\\'link\\', { name: \\'Anmelden\\' }).click();\\n  await page.getByLabel(\\'Benutzername *\\').click();\\n  await page.getByLabel(\\'Benutzername *\\').fill(\\'Admin\\');\\n  await page.getByLabel(\\'Benutzername *\\').press(\\'Tab\\');\\n  await page.getByPlaceholder(\\' \\').fill(\\'Admin\\');\\n  await page.getByRole(\\'button\\', { name: \\'Anmelden\\' }).click();\\n  await page.getByTestId(\\'create-workbook-button\\').click();\\n  \\n  // Wähle Repository \"Gewaesser\"\\n  await page.getByRole(\\'listitem\\', { name: \\'Gewaesser\\' }).click();\\n  \\n  // Wechsel zur nächsten Seite\\n  await page.click(\\'[data-testid=\"next-button\"]\\');\\n  \\n  // Füllen Sie das Formular aus\\n  await page.getByLabel(\\'Name des Arbeitsbuchs *\\').fill(\\'Arbeitsbuch Gewaesser\\');\\n  await page.getByLabel(\\'Beschreibung *\\').fill(\\'Beschreibung Gewaesser\\');\\n  \\n  // Speichern Sie das Arbeitsbuch\\n  await page.click(\\'[data-testid=\"save-button\"]\\');\\n  \\n  // Überprüfen Sie, ob das Arbeitsbuch erfolgreich gespeichert wurde\\n  await page.getByText(\\'Arbeitsbuch Gewaesser erfolgreich gespeichert\\').waitFor({ state: \\'visible\\' });\\n  \\n  // Speichern Sie das Arbeitsbuch als PDF\\n  await page.click(\\'[data-testid=\"download-button\"]\\');\\n  \\n  // Überprüfen Sie, ob das Arbeitsbuch erfolgreich heruntergeladen wurde\\n  await page.getByText(\\'Arbeitsbuch Gewaesser erfolgreich heruntergeladen\\').waitFor({ state: \\'visible\\' });\\n  \\n  // Speichern Sie das Arbeitsbuch als Excel-Datei\\n '\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In [3]:  answer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: '\\n[INST] \\nSchreiben Sie den Playwright-Code, um den folgenden Schritt eines UI-Tests auf der Cadenza-Website zu implementieren: [2.2]  wähle Repository \"Gewaesser\"..\\nVerwenden Sie die folgenden Ressourcen, um den Code zu erstellen:\\n1. Skript der vorherigen Schritte: import { test, expect } from \\'@playwright/test\\';\\nimport { writeFileSync } from \\'fs\\';\\ntest(\\'test\\', async ({ page }) => {\\n  await page.goto(\\'http://localhost:8080/cadenza/\\');\\n  await page.getByRole(\\'link\\', { name: \\'Anmelden\\' }).click();\\n  await page.getByLabel(\\'Benutzername *\\').click();\\n  await page.getByLabel(\\'Benutzername *\\').fill(\\'Admin\\');\\n  await page.getByLabel(\\'Benutzername *\\').press(\\'Tab\\');\\n  await page.getByPlaceholder(\\' \\').fill(\\'Admin\\');\\n  await page.getByRole(\\'button\\', { name: \\'Anmelden\\' }).click();\\n  await page.getByTestId(\\'create-workbook-button\\').click();\\n\\n});\\n2. HTML-Datei nach den vorherigen Schritten: \\n3. Screenshot nach den vorherigen Schritten:  \\nSchreiben Sie ausschließlich den Code für die Implementierung des nächsten gegebenen Schrittes.\\n[/INST] Um den nächsten Schritt \"wähle Repository \\'Gewaesser\\'\" auf der Cadenza-Website zu implementieren, können Sie den folgenden Code hinzufügen:\\n```javascript\\nawait page.getByRole(\\'link\\', { name: \\'Gewaesser\\' }).click();\\n```\\nDieser Code navigiert auf die Seite, die den Repository-Namen \"Gewaesser\" enthält. Bitte beachten Sie, dass Sie möglicherweise weitere Schritte hinzufügen müssen, um sicherzustellen, dass Sie auf die richtige Seite navigieren und dass Sie die gewünschten Einstellungen vornehmen können. '\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In [4]:  print(answer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] \n",
      "Schreiben Sie den Playwright-Code, um den folgenden Schritt eines UI-Tests auf der Cadenza-Website zu implementieren: [2.2]  wähle Repository \"Gewaesser\"..\n",
      "Verwenden Sie die folgenden Ressourcen, um den Code zu erstellen:\n",
      "1. Skript der vorherigen Schritte: import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByTestId('create-workbook-button').click();\n",
      "\n",
      "});\n",
      "2. HTML-Datei nach den vorherigen Schritten: \n",
      "3. Screenshot nach den vorherigen Schritten:  \n",
      "Schreiben Sie ausschließlich den Code für die Implementierung des nächsten gegebenen Schrittes.\n",
      "[/INST] Um den nächsten Schritt \"wähle Repository 'Gewaesser'\" auf der Cadenza-Website zu implementieren, können Sie den folgenden Code hinzufügen:\n",
      "```javascript\n",
      "await page.getByRole('link', { name: 'Gewaesser' }).click();\n",
      "```\n",
      "Dieser Code navigiert auf die Seite, die den Repository-Namen \"Gewaesser\" enthält. Bitte beachten Sie, dass Sie möglicherweise weitere Schritte hinzufügen müssen, um sicherzustellen, dass Sie auf die richtige Seite navigieren und dass Sie die gewünschten Einstellungen vornehmen können. \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "In [5]:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_10351/3405831235.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m zero\u001b[38;5;241m=\u001b[39m \u001b[43mextract_python_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_zero_shot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m one\u001b[38;5;241m=\u001b[39m extract_python_code(generated_one_shot, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m few\u001b[38;5;241m=\u001b[39m extract_python_code(generated_few_shot, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/tmp/ipykernel_10351/3098873528.py:11\u001b[0m, in \u001b[0;36mextract_python_code\u001b[0;34m(answer, filename, save)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matches:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Handle that the LLM is formatting the Comments wrong\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# matches = matches[-1] #last generated code.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     IPython\u001b[38;5;241m.\u001b[39membed()\n\u001b[0;32m---> 11\u001b[0m     python_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mmatches\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m())\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "zero= extract_python_code(generated_zero_shot, save=False)\n",
    "one= extract_python_code(generated_one_shot, save=False)\n",
    "few= extract_python_code(generated_few_shot, save=False)\n",
    "\n",
    "print(f\"Output zero shot:\\n {zero} \\n\\n\")\n",
    "print(f\"Output one shot:\\n {one} \\n\\n\")\n",
    "print(f\"Output few shot:\\n {few} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae1e51cc-1384-405d-9f0d-821dba8a8f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import { test, expect } from '@playwright/test';\n",
      "import { writeFileSync } from 'fs';\n",
      "test('test', async ({ page }) => {\n",
      "  await page.goto('http://localhost:8080/cadenza/');\n",
      "  await page.getByRole('link', { name: 'Anmelden' }).click();\n",
      "  await page.getByLabel('Benutzername *').click();\n",
      "  await page.getByLabel('Benutzername *').fill('Admin');\n",
      "  await page.getByLabel('Benutzername *').press('Tab');\n",
      "  await page.getByPlaceholder(' ').fill('Admin');\n",
      "  await page.getByRole('button', { name: 'Anmelden' }).click();\n",
      "  await page.getByTestId('create-workbook-button').click();\n",
      "  await page.getByRole('menuitem', { name: 'Gewässer' }).click();\n",
      "});\n"
     ]
    }
   ],
   "source": [
    "print(test_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f04350-8f7a-4283-9cb2-1c389aed9663",
   "metadata": {},
   "source": [
    "No really close to the original script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc6efe-83f9-4246-bc24-c8deb23b396a",
   "metadata": {},
   "source": [
    "## 2.5 Process all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06204bfb-373f-41f0-8d58-6b317dd58591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to iterate all elements and do the prompting\n",
    "prompt_template = '''\n",
    "[INST] \n",
    "Schreiben Sie den Playwright-Code, um den folgenden Schritt eines UI-Tests auf der Cadenza-Website zu implementieren: {last_step}.\n",
    "Verwenden Sie die folgenden Ressourcen, um den Code zu erstellen:\n",
    "1. Skript der vorherigen Schritte: {test_script_p}\n",
    "2. HTML-Datei nach den vorherigen Schritten: {html_reduce_p}\n",
    "3. Screenshot nach den vorherigen Schritten: <image>\n",
    "Schreiben Sie ausschließlich den Code für die Implementierung des nächsten gegebenen Schrittes.\n",
    "[/INST]\n",
    "'''\n",
    "prompt_output = '''\n",
    "```javascript\n",
    "{test_script}\n",
    "```\n",
    "'''\n",
    "def prompt_generation(items, prompt_template, prompt_output, shots=0):\n",
    "    prompts = []\n",
    "    images = []\n",
    "    labels = []\n",
    "    file_names = []\n",
    "    for item in items:\n",
    "        prompt = ''\n",
    "        img = []\n",
    "        if shots != 0:\n",
    "            # Find examples for few shot prompting\n",
    "            most_similar_tests = find_most_similar_tests(item, n=shots)\n",
    "            for example in most_similar_tests:\n",
    "                steps_e, expected_result_e, html_content_e, image_e, test_script_e = extract_content_for_database_item(example)\n",
    "                steps_p_e, expected_result_p_e, html_content_p_e, image_p_e, test_script_p_e = extract_content_for_previous_database_item(example)\n",
    "                last_step_e = get_last_step(example)\n",
    "                html_reduce_p_e = reduce_html_spacy(html_content_p_e, last_step_e)\n",
    "                prompt_filled = prompt_template.format(\n",
    "                                last_step=last_step_e,\n",
    "                                test_script_p=test_script_p_e,\n",
    "                                html_reduce_p=html_reduce_p_e,\n",
    "                                )\n",
    "                prompt_filled_output = prompt_output.format(\n",
    "                                test_script=test_script_e,\n",
    "                                )\n",
    "                prompt += prompt_filled + \"\\n\" + prompt_filled_output + \"\\n\"\n",
    "                img.append(image_p_e)\n",
    "        # Load actual\n",
    "        steps, expected_result, html_content, image, test_script = extract_content_for_database_item(item)\n",
    "        steps_p, expected_result_p, html_content_p, image_p, test_script_p = extract_content_for_previous_database_item(item)\n",
    "        last_step = get_last_step(item)\n",
    "        html_reduce_p = reduce_html_spacy(html_content_p, last_step)\n",
    "        prompt_filled = prompt_template.format(\n",
    "                                last_step=last_step,\n",
    "                                test_script_p=test_script_p,\n",
    "                                html_reduce_p=html_reduce_p,\n",
    "                                )\n",
    "        # Save actual\n",
    "        prompt += prompt_filled\n",
    "        img.append(image)\n",
    "\n",
    "        # Save in global list\n",
    "        prompts.append(prompt)\n",
    "        images.append(img)\n",
    "        labels.append(test_script)\n",
    "        file_names.append(item[0].replace(\".\", \"_\") + \".ts\")\n",
    "    return prompts, images, labels, file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b68ea-dddf-4340-b7ac-5bbb886b0d17",
   "metadata": {},
   "source": [
    "### 2.5.1 Zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "26dbb5db-f422-4c88-a5e6-398effd44833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10351/2920275253.py:31: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  elements = soup.find_all(tag, attrs={attribute: True}, text=lambda t: t and text in t.lower())\n"
     ]
    }
   ],
   "source": [
    "prompts, images, labels, file_names = prompt_generation(items, prompt_template, prompt_output, shots=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ad87f693-3455-4ba1-a133-d2f44191fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:   0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   1%|          | 1/100 [00:40<1:06:25, 40.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   2%|▏         | 2/100 [00:49<36:00, 22.04s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   3%|▎         | 3/100 [00:57<25:29, 15.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   4%|▍         | 4/100 [01:06<20:36, 12.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   5%|▌         | 5/100 [01:33<28:42, 18.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   6%|▌         | 6/100 [01:46<25:26, 16.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   7%|▋         | 7/100 [02:10<29:17, 18.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   8%|▊         | 8/100 [02:20<24:20, 15.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   9%|▉         | 9/100 [02:58<34:45, 22.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  10%|█         | 10/100 [03:10<29:13, 19.49s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  11%|█         | 11/100 [03:23<25:55, 17.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  12%|█▏        | 12/100 [03:59<33:52, 23.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  13%|█▎        | 13/100 [04:09<27:44, 19.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  14%|█▍        | 14/100 [04:17<22:55, 15.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  15%|█▌        | 15/100 [04:28<20:25, 14.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  16%|█▌        | 16/100 [05:07<30:25, 21.73s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  17%|█▋        | 17/100 [05:16<24:38, 17.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  18%|█▊        | 18/100 [05:24<20:25, 14.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  19%|█▉        | 19/100 [05:32<17:33, 13.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  20%|██        | 20/100 [05:40<15:17, 11.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  21%|██        | 21/100 [05:53<15:42, 11.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  22%|██▏       | 22/100 [06:04<15:09, 11.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  23%|██▎       | 23/100 [06:32<21:01, 16.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  24%|██▍       | 24/100 [06:40<17:31, 13.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  25%|██▌       | 25/100 [07:18<26:37, 21.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  26%|██▌       | 26/100 [07:28<22:09, 17.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  27%|██▋       | 27/100 [07:37<18:30, 15.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  28%|██▊       | 28/100 [07:46<15:49, 13.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  29%|██▉       | 29/100 [07:57<15:00, 12.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  30%|███       | 30/100 [08:11<15:09, 12.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  31%|███       | 31/100 [08:24<14:59, 13.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  32%|███▏      | 32/100 [08:33<13:20, 11.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  33%|███▎      | 33/100 [08:45<13:16, 11.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  34%|███▍      | 34/100 [08:55<12:20, 11.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  35%|███▌      | 35/100 [09:04<11:23, 10.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  36%|███▌      | 36/100 [09:12<10:41, 10.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  37%|███▋      | 37/100 [09:26<11:30, 10.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  38%|███▊      | 38/100 [09:34<10:39, 10.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  39%|███▉      | 39/100 [09:42<09:44,  9.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  40%|████      | 40/100 [10:12<15:45, 15.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  41%|████      | 41/100 [10:21<13:21, 13.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  42%|████▏     | 42/100 [10:29<11:31, 11.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  43%|████▎     | 43/100 [10:56<15:44, 16.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  44%|████▍     | 44/100 [11:25<18:42, 20.05s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  45%|████▌     | 45/100 [11:54<20:52, 22.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  46%|████▌     | 46/100 [12:03<16:53, 18.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  47%|████▋     | 47/100 [12:31<18:51, 21.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  48%|████▊     | 48/100 [12:48<17:24, 20.08s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  49%|████▉     | 49/100 [12:57<14:12, 16.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  50%|█████     | 50/100 [13:24<16:37, 19.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  51%|█████     | 51/100 [13:36<14:18, 17.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  52%|█████▏    | 52/100 [13:51<13:32, 16.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  53%|█████▎    | 53/100 [14:00<11:16, 14.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  54%|█████▍    | 54/100 [14:14<10:57, 14.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  55%|█████▌    | 55/100 [14:41<13:41, 18.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  56%|█████▌    | 56/100 [14:53<11:58, 16.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  57%|█████▋    | 57/100 [15:01<09:57, 13.88s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  58%|█████▊    | 58/100 [15:10<08:33, 12.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  59%|█████▉    | 59/100 [15:37<11:29, 16.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  60%|██████    | 60/100 [15:52<10:46, 16.16s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  61%|██████    | 61/100 [16:00<08:56, 13.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  62%|██████▏   | 62/100 [16:12<08:23, 13.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  63%|██████▎   | 63/100 [16:51<12:54, 20.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  64%|██████▍   | 64/100 [16:59<10:15, 17.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  65%|██████▌   | 65/100 [17:06<08:15, 14.15s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  66%|██████▌   | 66/100 [17:14<06:48, 12.02s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  67%|██████▋   | 67/100 [17:21<05:55, 10.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  68%|██████▊   | 68/100 [17:30<05:19, 10.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  69%|██████▉   | 69/100 [18:08<09:38, 18.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  70%|███████   | 70/100 [18:19<08:03, 16.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  71%|███████   | 71/100 [18:26<06:35, 13.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  72%|███████▏  | 72/100 [18:39<06:15, 13.40s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  73%|███████▎  | 73/100 [19:21<09:49, 21.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  74%|███████▍  | 74/100 [19:30<07:50, 18.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  75%|███████▌  | 75/100 [19:48<07:30, 18.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  76%|███████▌  | 76/100 [20:26<09:38, 24.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  77%|███████▋  | 77/100 [20:34<07:18, 19.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  78%|███████▊  | 78/100 [20:56<07:22, 20.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  79%|███████▉  | 79/100 [21:07<06:00, 17.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  80%|████████  | 80/100 [21:17<05:02, 15.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  81%|████████  | 81/100 [21:33<04:51, 15.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  82%|████████▏ | 82/100 [21:44<04:15, 14.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  83%|████████▎ | 83/100 [21:53<03:32, 12.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  84%|████████▍ | 84/100 [22:09<03:36, 13.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  85%|████████▌ | 85/100 [22:20<03:13, 12.90s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  86%|████████▌ | 86/100 [22:29<02:44, 11.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  87%|████████▋ | 87/100 [23:11<04:28, 20.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  88%|████████▊ | 88/100 [23:20<03:27, 17.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  89%|████████▉ | 89/100 [23:33<02:55, 15.91s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  90%|█████████ | 90/100 [24:09<03:40, 22.03s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  91%|█████████ | 91/100 [24:22<02:54, 19.39s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  92%|█████████▏| 92/100 [25:00<03:18, 24.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  93%|█████████▎| 93/100 [25:09<02:19, 19.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  94%|█████████▍| 94/100 [25:16<01:36, 16.12s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  95%|█████████▌| 95/100 [25:52<01:51, 22.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  96%|█████████▌| 96/100 [26:24<01:39, 24.96s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  97%|█████████▋| 97/100 [26:35<01:02, 20.81s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  98%|█████████▊| 98/100 [27:01<00:44, 22.45s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  99%|█████████▉| 99/100 [27:24<00:22, 22.67s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts: 100%|██████████| 100/100 [27:33<00:00, 16.53s/it]\n"
     ]
    }
   ],
   "source": [
    "bleu = []\n",
    "root = \"./generated_script/zero_shot/\"\n",
    "for prompt, image, label, file_name in tqdm(zip(prompts, images, labels, file_names), total=len(prompts), desc=\"Processing prompts\"):\n",
    "    # Feed foward pass\n",
    "    inputs = processor(prompt, image, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(**inputs, max_new_tokens=500)\n",
    "    generated = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    path = root + file_name\n",
    "    code = extract_python_code(generated, path, save=True)\n",
    "\n",
    "    #Extract python code\n",
    "    generated_script = clean_code(code)\n",
    "    bleu_score = sentence_bleu([clean_code(test_script).split()], label.split())\n",
    "    bleu.append(bleu_score)\n",
    "\n",
    "bleu_zero = bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "73689c27-1de5-427a-9b31-e8acfee8531e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5651809220636579"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Average\n",
    "sum(bleu_zero) / len(bleu_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a50341-82c2-4e27-83da-d47a72044967",
   "metadata": {},
   "source": [
    "### 2.5.2 One shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "152e40c2-2aa7-4757-8e71-8c44fdaa97b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10351/2920275253.py:31: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  elements = soup.find_all(tag, attrs={attribute: True}, text=lambda t: t and text in t.lower())\n"
     ]
    }
   ],
   "source": [
    "prompts, images, labels, file_names = prompt_generation(items, prompt_template, prompt_output, shots=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5e13d23b-fc24-4f2f-abe8-160c577a06c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing prompts:   0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   1%|          | 1/100 [01:00<1:39:01, 60.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   2%|▏         | 2/100 [01:10<50:40, 31.03s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   3%|▎         | 3/100 [02:00<1:04:19, 39.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   4%|▍         | 4/100 [02:53<1:11:26, 44.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   5%|▌         | 5/100 [03:31<1:07:18, 42.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   6%|▌         | 6/100 [04:21<1:10:14, 44.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   7%|▋         | 7/100 [05:20<1:16:45, 49.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   8%|▊         | 8/100 [06:12<1:17:26, 50.51s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:   9%|▉         | 9/100 [07:09<1:19:40, 52.54s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  10%|█         | 10/100 [07:42<1:09:38, 46.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  11%|█         | 11/100 [08:35<1:11:42, 48.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  12%|█▏        | 12/100 [09:26<1:12:01, 49.11s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  13%|█▎        | 13/100 [10:18<1:12:27, 49.97s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  14%|█▍        | 14/100 [11:09<1:12:21, 50.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  15%|█▌        | 15/100 [12:01<1:12:09, 50.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  16%|█▌        | 16/100 [12:43<1:07:26, 48.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  17%|█▋        | 17/100 [13:36<1:08:37, 49.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  18%|█▊        | 18/100 [14:29<1:08:58, 50.47s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  19%|█▉        | 19/100 [15:21<1:08:52, 51.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  20%|██        | 20/100 [16:13<1:08:29, 51.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  21%|██        | 21/100 [16:48<1:01:01, 46.35s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  22%|██▏       | 22/100 [17:47<1:05:28, 50.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  23%|██▎       | 23/100 [18:38<1:04:42, 50.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  24%|██▍       | 24/100 [19:11<57:15, 45.20s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  25%|██▌       | 25/100 [20:11<1:02:02, 49.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  26%|██▌       | 26/100 [21:04<1:02:27, 50.64s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  27%|██▋       | 27/100 [21:56<1:02:10, 51.10s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  28%|██▊       | 28/100 [22:43<59:43, 49.78s/it]  Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  29%|██▉       | 29/100 [23:35<59:55, 50.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  30%|███       | 30/100 [24:28<59:50, 51.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  31%|███       | 31/100 [25:04<53:46, 46.76s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  32%|███▏      | 32/100 [25:17<41:28, 36.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  33%|███▎      | 33/100 [26:04<44:05, 39.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  34%|███▍      | 34/100 [26:55<47:20, 43.04s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  35%|███▌      | 35/100 [27:46<49:21, 45.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Processing prompts:  35%|███▌      | 35/100 [28:01<52:03, 48.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_10351/1571684118.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt, image, label, file_name \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mzip\u001b[39m(prompts, images, labels, file_names), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(prompts), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Feed foward pass\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m processor(prompt, image, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     generated \u001b[38;5;241m=\u001b[39m processor\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m     path \u001b[38;5;241m=\u001b[39m root \u001b[38;5;241m+\u001b[39m file_name\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1914\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1906\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1907\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1908\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1909\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1911\u001b[0m     )\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1914\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1931\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:2651\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2648\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2651\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2652\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2653\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2654\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2655\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2656\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2659\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llava_next/modeling_llava_next.py:855\u001b[0m, in \u001b[0;36mLlavaNextForConditionalGeneration.forward\u001b[0;34m(self, input_ids, pixel_values, image_sizes, attention_mask, position_ids, past_key_values, inputs_embeds, vision_feature_layer, vision_feature_select_strategy, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    851\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((extended_attention_mask, attention_mask[:, \u001b[38;5;241m-\u001b[39mtarget_length:]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    853\u001b[0m         position_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(attention_mask, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 855\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlanguage_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    868\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:1200\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1197\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1200\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1214\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:976\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    965\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    966\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    967\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    973\u001b[0m         cache_position,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 976\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:718\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/mistral/modeling_mistral.py:659\u001b[0m, in \u001b[0;36mMistralSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    657\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 659\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m, past_key_value\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:470\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    467\u001b[0m bias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    468\u001b[0m out \u001b[38;5;241m=\u001b[39m bnb\u001b[38;5;241m.\u001b[39mmatmul_4bit(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mt(), bias\u001b[38;5;241m=\u001b[39mbias, quant_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mquant_state)\n\u001b[0;32m--> 470\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bleu = []\n",
    "root = \"./generated_script/one_shot/\"\n",
    "for prompt, image, label, file_name in tqdm(zip(prompts, images, labels, file_names), total=len(prompts), desc=\"Processing prompts\"):\n",
    "    # Feed foward pass\n",
    "    inputs = processor(prompt, image, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(**inputs, max_new_tokens=500)\n",
    "    generated = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    path = root + file_name\n",
    "    code = extract_python_code(generated, path, save=True)\n",
    "\n",
    "    #Extract python code\n",
    "    generated_script = clean_code(code)\n",
    "    bleu_score = sentence_bleu([clean_code(test_script).split()], label.split())\n",
    "    bleu.append(bleu_score)\n",
    "\n",
    "bleu_one = bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf516b-9cd6-473b-9fc6-2c7c311d0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average\n",
    "sum(bleu_one) / len(bleu_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d850c6-08eb-4dad-b3f5-97fa36f78910",
   "metadata": {},
   "source": [
    "### 2.5.3 Few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7d758-03bd-4c8a-b78f-10b0d4c7edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts, images, labels, file_names = prompt_generation(items, prompt_template, prompt_output, shots=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b21cf4-aac6-4dcc-a7a4-274b5d3f65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = []\n",
    "root = \"./generated_script/few_shot/\"\n",
    "for prompt, image, label, file_name in tqdm(zip(prompts, images, labels, file_names), total=len(prompts), desc=\"Processing prompts\"):\n",
    "    # Feed foward pass\n",
    "    inputs = processor(prompt, image, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(**inputs, max_new_tokens=500)\n",
    "    generated = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    path = root + file_name\n",
    "    code = extract_python_code(generated, path, save=True)\n",
    "\n",
    "    #Extract python code\n",
    "    generated_script = clean_code(code)\n",
    "    bleu_score = sentence_bleu([clean_code(test_script).split()], label.split())\n",
    "    bleu.append(bleu_score)\n",
    "\n",
    "bleu_few = bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e6557-6529-4ce1-b951-4a8a430f9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average\n",
    "sum(bleu_few) / len(bleu_few)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
