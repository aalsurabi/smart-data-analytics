{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683a90f6-4a88-40d4-8f80-2acdc1edace3",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9357a2-e2b0-4536-b3ac-11bc26d8cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting trl\n",
      "  Downloading trl-0.9.4-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from trl) (2.2.2+cu121)\n",
      "Collecting transformers>=4.31.0 (from trl)\n",
      "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.11/site-packages (from trl) (1.26.4)\n",
      "Collecting accelerate (from trl)\n",
      "  Downloading accelerate-0.31.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets (from trl)\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting tyro>=0.5.11 (from trl)\n",
      "  Downloading tyro-0.8.5-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.4.127)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.31.0->trl)\n",
      "  Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m239.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.20,>=0.19 (from transformers>=4.31.0->trl)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.31.0->trl)\n",
      "  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting docstring-parser>=0.16 (from tyro>=0.5.11->trl)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n",
      "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate->trl) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (2.2.1)\n",
      "Collecting requests (from huggingface_hub)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.42.1 (from huggingface_hub)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets->trl)\n",
      "  Downloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->trl)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.6/402.6 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m128.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.9.4-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m542.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.8.5-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m418.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m532.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m189.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m474.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m502.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.0/785.0 kB\u001b[0m \u001b[31m146.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m127.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m483.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m532.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, xxhash, tqdm, shtab, safetensors, requests, regex, multiprocess, docstring-parser, huggingface_hub, tyro, tokenizers, transformers, datasets, accelerate, trl\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.2\n",
      "    Uninstalling tqdm-4.66.2:\n",
      "      Successfully uninstalled tqdm-4.66.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed accelerate-0.31.0 datasets-2.20.0 docstring-parser-0.16 huggingface_hub-0.23.4 multiprocess-0.70.16 regex-2024.5.15 requests-2.32.3 safetensors-0.4.3 sentencepiece-0.2.0 shtab-1.7.1 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.41.2 trl-0.9.4 tyro-0.8.5 xxhash-3.4.1\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.2.2+cu121)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.41.2)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (0.31.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.1\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting flash_attn\n",
      "  Downloading flash_attn-2.5.9.post1.tar.gz (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from flash_attn) (2.2.2+cu121)\n",
      "Collecting einops (from flash_attn)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (4.11.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch->flash_attn) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash_attn) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->flash_attn) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->flash_attn) (1.3.0)\n",
      "Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m170.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: flash_attn\n",
      "  Building wheel for flash_attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash_attn: filename=flash_attn-2.5.9.post1-cp311-cp311-linux_x86_64.whl size=120841148 sha256=1410877098be9aca61b564778be6217f428eeccceb82fa09789fc327f4770e4e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rjvj7nc8/wheels/af/50/20/ce81323c17416ebfc55d5c9015d34b368c733ef262fa8d7b61\n",
      "Successfully built flash_attn\n",
      "Installing collected packages: einops, flash_attn\n",
      "Successfully installed einops-0.8.0 flash_attn-2.5.9.post1\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
      "  Downloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.7.4-py3-none-any.whl.metadata (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (24.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.18.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.17.2)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Downloading spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m357.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m538.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m509.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 kB\u001b[0m \u001b[31m248.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (490 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.9/490.9 kB\u001b[0m \u001b[31m178.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.2/920.2 kB\u001b[0m \u001b[31m139.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m429.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m304.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.18.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m360.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m472.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marisa_trie-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m138.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, shellingham, pydantic-core, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, annotated-types, srsly, pydantic, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed annotated-types-0.7.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.18.1 confection-0.1.5 cymem-2.0.8 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.2.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.7.4 pydantic-core-2.18.4 shellingham-1.5.4 smart-open-7.0.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.5 typer-0.12.3 wasabi-1.1.3 weasel-0.4.1\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting de-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.11/site-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.7.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (69.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.17.2)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub sentencepiece trl\n",
    "!pip install torch transformers bitsandbytes accelerate\n",
    "!pip install flash_attn\n",
    "!pip install spacy\n",
    "!python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4431b4-70e4-442a-9a2f-f0eea165420f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 13:23:04.871990: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-27 13:23:04.911521: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-27 13:23:05.673387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from transformers import pipeline\n",
    "from trl import setup_chat_format,SFTTrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc177a33-b22d-40f9-b4b4-032b0d801605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2+cu121'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da69a2a4-ba9a-4344-a4aa-eba87208b5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/jovyan/.cache/huggingface/token\n",
      "Login successful\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Call the login function to authenticate. You'll need to enter your credentials or token.\n",
    "token = \"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\"\n",
    "login(token=token)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e962cb-1051-4a48-8863-ce6c771faabc",
   "metadata": {},
   "source": [
    "# 1. Model trys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19338a3d-47b1-40a8-886f-d788ec581ac0",
   "metadata": {},
   "source": [
    "We tried using Meta-Llama 8B, but it was too heavy, causing the kernel to shut down. The same issue occurred with Mistal; the model is too large.\n",
    "\n",
    "Tutorial from huggingface => https://huggingface.co/docs/transformers/llm_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637b82b-7310-48b1-972e-d3c5515a3e50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.1 Meta-LLama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b329061-c742-4dc5-9c18-ae972a660c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the model name\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "# # Load the tokenizer and model with token\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, token=token).to(device)\n",
    "\n",
    "# # Define the prompt\n",
    "# prompt = \"\"\"\n",
    "# Generate a Playwright script in TypeScript that does the following:\n",
    "# 1. Navigate to eBay Kleinanzeigen\n",
    "# 2. Accept cookies\n",
    "# 3. Accept the GDPR banner\n",
    "# 4. Search for a phone\n",
    "# 5. Take a screenshot of the search results\n",
    "# \"\"\"\n",
    "\n",
    "# # Tokenize the input\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# # Generate the script\n",
    "# outputs = model.generate(inputs.input_ids, max_length=500, num_return_sequences=1)\n",
    "\n",
    "# # Decode and print the generated text\n",
    "# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb23d2c7-c430-4c35-a0fd-7b76f78f9bcb",
   "metadata": {},
   "source": [
    "## 1.2 GPT-Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ea5c15-206e-413e-aa2a-c8c9b0013494",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-1.3B\" # Model name for GPT-1.3\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8823e729-1c6f-4f41-885b-69285f299b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  198,  8645,   378,   257, 11361,  4226,  1262,   262,  3811, 29995,\n",
      "          5888,   284,  1620, 12454,  4856,   319,  7444,    13,   220,   198,\n",
      "           464,  4226,   815,    25,   198,    16,    13, 13244, 10055,   284,\n",
      "           262,  7444, 35699,    13,   198,    17,    13, 21699, 14746,    13,\n",
      "           198,    18,    13, 11140,   329,   257,  2008,    13,   198,    19,\n",
      "            13,  7214,   257, 22032,   286,   262,  2989,  2482,    13,   198,\n",
      "           464,  2163,   815,   923,   355,  5679,    25,   198,  4299,  1332,\n",
      "            62, 11604,     7,  7700,    25,  7873,  2599,   198]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt\n",
    "prompt = \"\"\"\n",
    "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
    "The script should:\n",
    "1. Navigate to the YouTube webpage.\n",
    "2. Accept cookies.\n",
    "3. Search for a video.\n",
    "4. Take a screenshot of the search results.\n",
    "The function should start as follows:\n",
    "def test_youtube(page: Page):\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize input\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79eda90-4aaf-40de-b591-21472c6b580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "outputs = model.generate(input_ids=input_ids, \n",
    "                         pad_token_id=tokenizer.eos_token_id,  # Set pad token ID to EOS token ID\n",
    "                         attention_mask=input_ids.new_ones(input_ids.shape).to(device),  # Create attention mask\n",
    "                         max_length=500,\n",
    "                         do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95920567-1eae-4f0a-8c92-aab75968fd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
      "The script should:\n",
      "1. Navigate to the YouTube webpage.\n",
      "2. Accept cookies.\n",
      "3. Search for a video.\n",
      "4. Take a screenshot of the search results.\n",
      "The function should start as follows:\n",
      "def test_youtube(page: Page):\n",
      "    video_url = page.url\n",
      "    response = browser.get(video_url, params={'no_result' : True})\\\n",
      "    page\\\n",
      "     -> wait_for_page_to_load(video_url)\\\n",
      "     -> assert response(video_url).text\n",
      "\n",
      "I have a problem with the wait_for_page_to_load in the first line (line \\), because I always create the page before performing the test and the page isn't always available. I have tried to put it inside \\ if it was always available: but it is not.\n",
      "So, I need to wait for the video to appear, but I can't wait for the page to be ready. Can you please help me?\n",
      "\n",
      "A:\n",
      "\n",
      "The correct wait\\_for_page_to_load function to use is one you wrote (without the () on line \\).\n",
      "\n",
      "wait_for_page_to_load(page) - waits until page will be updated with status True or False. This is an absolute requirement.\n",
      "\n",
      "import requests\n",
      "from playwright.tools import wait_until, create_page as pagecreate\n",
      "wait_until(page.open)\n",
      "page.open = True\n",
      "\n",
      "However, because you don't specify if there is content waiting to be displayed or not, that will still be true regardless of the fact that a page is found\n",
      "\n",
      "A:\n",
      "\n",
      "Your code needs to wait until it can find the Youtube page at the URL you give.  If you only give it a string, it will still attempt to find it but will fail.\n",
      "For example, the following will not find your page:\n",
      "try:\n",
      "    response = browser.get(r'https://www.youtube.com/watch?v=CiOq_ZsXwEo')\n",
      "except urlopen:\n",
      "    continue\n",
      "\n",
      "Instead you have to give it a list of the pages\n"
     ]
    }
   ],
   "source": [
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c1fd4-1bbb-4143-bdd4-d9e06ce58a0e",
   "metadata": {},
   "source": [
    "It do something, but i dont think it can the code, seems wrong. But with finetuning the model ca do better. Also a lot of text and not so much code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d2a7e-05d4-40e6-9358-b0830bfef923",
   "metadata": {},
   "source": [
    "## 1.3 CodeT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75192e08-3dc9-421d-aa1b-2305a6c739a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a769a6f4-0a2f-4a15-9cb5-6097534f3689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test yourscreenshot for you\"_test_youtube\" : function ( )] ; #YouTube app}page.onclick (Page: Page:) {0 ] }'_test_youtube' : \"\"\"Test a YouTubetest_youtube(. test_youtube }\n"
     ]
    }
   ],
   "source": [
    "# Define the input text with the updated prompt\n",
    "text = \"\"\"\n",
    "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
    "The script should:\n",
    "1. Navigate to the YouTube webpage.\n",
    "2. Accept cookies.\n",
    "3. Search for a video.\n",
    "4. Take a screenshot of the search results.\n",
    "The function should start as follows:\n",
    "def test_youtube(page: Page):\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "input_ids = inputs.input_ids\n",
    "attention_mask = inputs.attention_mask\n",
    "\n",
    "# Generate the Python script\n",
    "generated_ids = model.generate(input_ids = input_ids,\n",
    "                               attention_mask = attention_mask,\n",
    "                               max_length=500,\n",
    "                               do_sample=True)  # Adjust max_length as needed\n",
    "generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated Python script\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a5f41-435e-4899-9164-64ba243ba8f5",
   "metadata": {},
   "source": [
    "Like in gpt. To model do something, but the model it is not fitted do this, it can do better. Sometimes to model predict random stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fc8cd-317e-4ba4-ba11-3b47d3aac8d5",
   "metadata": {},
   "source": [
    "## 1.4 Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d1750-4cc0-47d3-b0a3-0f35ec32b513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef339deca9fb4359bbc2e391d6787d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8ebb5d7b1941b880ab42f86a3e5d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:  25%|##4       | 1.13G/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411bfa7996234c54ba72ec26cbd9f303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.3\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ee911-ec57-4b21-8504-8a957933581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4fe28-5df1-4d7c-a67a-507472ca1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input text with the updated prompt\n",
    "text = \"\"\"\n",
    "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
    "The script should:\n",
    "1. Navigate to the YouTube webpage.\n",
    "2. Accept cookies.\n",
    "3. Search for a video.\n",
    "4. Take a screenshot of the search results.\n",
    "The function should start as follows:\n",
    "def test_youtube(page: Page):\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "# input_ids = inputs.input_ids\n",
    "# attention_mask = inputs.attention_mask\n",
    "\n",
    "# # Generate the Python script\n",
    "# generated_ids = model.generate(input_ids = input_ids,\n",
    "#                                attention_mask = attention_mask,\n",
    "#                                max_length=500,\n",
    "#                                do_sample=True)  # Adjust max_length as needed\n",
    "# generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# # Print the generated Python script\n",
    "# print(generated_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a68a1-7d1b-4741-9b89-d6a3914f56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b823c7f-c5a6-4b0a-ab31-d8ad49d79c78",
   "metadata": {},
   "source": [
    "# 2. Multimodal Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c5e86-98b5-4624-a1e1-71b92186770c",
   "metadata": {},
   "source": [
    "## 2.1 Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8902d5-2b0b-4faf-a4b9-0fad1ad96703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "from PIL import Image\n",
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration, BitsAndBytesConfig\n",
    "import torch\n",
    "import spacy\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc8124-8cb4-4b65-a52a-4f67ffa55a3f",
   "metadata": {},
   "source": [
    "## 2.2 Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e937eb0-338e-4ea9-a13f-11c47e12fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_html_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    return html_content\n",
    "\n",
    "def reduce_html_by_tag(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Remove head element\n",
    "    head_tag = soup.find('head')\n",
    "    if head_tag:\n",
    "        head_tag.decompose()\n",
    "\n",
    "    # Remove footer element\n",
    "    footer_tag = soup.find('footer')\n",
    "    if footer_tag:\n",
    "        footer_tag.decompose()\n",
    "\n",
    "    # Remove nav elements\n",
    "    for nav_tag in soup.find_all('nav'):\n",
    "        nav_tag.decompose()\n",
    "\n",
    "    # Remove aside elements\n",
    "    for aside_tag in soup.find_all('aside'):\n",
    "        aside_tag.decompose()\n",
    "\n",
    "    # Remove header elements\n",
    "    for header_tag in soup.find_all('header'):\n",
    "        header_tag.decompose()\n",
    "\n",
    "    # Remove comments\n",
    "    for comment in soup.find_all(text=lambda text: isinstance(text, Comment)):\n",
    "        comment.extract()\n",
    "\n",
    "    # Remove meta tags\n",
    "    for meta_tag in soup.find_all('meta'):\n",
    "        meta_tag.decompose()\n",
    "\n",
    "    # Remove script tags\n",
    "    for script_tag in soup.find_all('script'):\n",
    "        script_tag.decompose()\n",
    "\n",
    "    # Remove link tags\n",
    "    for link_tag in soup.find_all('link'):\n",
    "        link_tag.decompose()\n",
    "\n",
    "    return soup.prettify()\n",
    "\n",
    "# Load spaCy model for German keyword extraction\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "def reduce_html_spacy(html_content, description):\n",
    "    \"\"\"\n",
    "    Extracts keywords from the description, searches the HTML content for these keywords, \n",
    "    and returns the simplified HTML containing the relevant sections.\n",
    "    \n",
    "    Args:\n",
    "    html_content (str): The HTML content of the webpage.\n",
    "    description (str): The task description.\n",
    "    \n",
    "    Returns:\n",
    "    str: The simplified HTML containing the relevant sections.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract keywords from the description\n",
    "    doc = nlp(description)\n",
    "    keywords = [token.text for token in doc if token.pos_ not in {'VERB', 'ADP', 'PUNCT', 'NUM', 'SYM', 'X', 'DET'} and not token.is_punct]\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Function to find elements containing specific text\n",
    "    def find_elements_by_text(soup, text):\n",
    "        elements = soup.find_all(string=lambda t: text in t)\n",
    "        return elements\n",
    "\n",
    "    # Dictionary to hold found elements\n",
    "    found_elements = {}\n",
    "\n",
    "    for keyword in keywords:\n",
    "        found_elements[keyword] = find_elements_by_text(soup, keyword)\n",
    "\n",
    "    # Collect extracted HTML sections\n",
    "    extracted_html_sections = []\n",
    "\n",
    "    for keyword, elements in found_elements.items():\n",
    "        if elements:\n",
    "            for element in elements:\n",
    "                parent = element.find_parent()\n",
    "                extracted_html = parent.prettify()\n",
    "                extracted_html_sections.append(extracted_html)\n",
    "        else:\n",
    "            print(f\"No elements found for keyword '{keyword}'\")\n",
    "\n",
    "    # Combine all extracted sections into one HTML string\n",
    "    simplified_html = \"\\n\".join(extracted_html_sections)\n",
    "    \n",
    "    return simplified_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71450ab8-993b-4bd1-8fd6-9ac578cae7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_previous_test_item (target_item):\n",
    "    steps = target_item[1] \n",
    "    previous_item = None\n",
    "    for item in items:\n",
    "        steps_to_compare = item[1]\n",
    "        longest_steps_to_compare_length = 0\n",
    "        if steps_to_compare in steps and not steps_to_compare == steps and len(steps_to_compare) > longest_steps_to_compare_length:\n",
    "            longest_steps_to_compare_length = len (steps_to_compare)\n",
    "            previous_item = item\n",
    "    return previous_item\n",
    "\n",
    "def extract_content_for_database_item(item):\n",
    "    random_item = item\n",
    "    steps = random_item[1]\n",
    "    expected_result = random_item[2]\n",
    "    \n",
    "    html_file_path = '.'+ random_item[3].replace('\\\\', '/')[1:]\n",
    "    html_content = load_html_file(html_file_path)\n",
    "    \n",
    "    image_path = '.'+random_item[4].replace('\\\\', '/')[1:]\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    test_script_path = '.'+random_item[5].replace('\\\\', '/')[1:]\n",
    "    test_script = open(test_script_path, 'r', encoding='utf-8').read()\n",
    "\n",
    "    return steps, expected_result, html_content, image, test_script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cd2cef-0881-45b7-aa0b-c17524c1ee08",
   "metadata": {},
   "source": [
    "## 2.3 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e766c321-b7e4-4a3c-8181-742d42412ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0770389babd04c608413d7e39663393e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quantization for low memory usage\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_8bit=True,  # Enable 8-bit quantization\n",
    "#     llm_int8_threshold=6.0  # Optional: fine-tune the threshold\n",
    "# )\n",
    "processor = LlavaNextProcessor.from_pretrained(\"llava-hf/llava-v1.6-mistral-7b-hf\")\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    \"llava-hf/llava-v1.6-mistral-7b-hf\", \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True,\n",
    "    attn_implementation=\"flash_attention_2\",  # Updated deprecated parameter\n",
    "    quantization_config=quantization_config  # Pass the quantization config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e0e092-e402-43ad-a82b-781fdbe4f8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]  \n",
      "Please write a python code for a UI test using playwright. [/INST] To create a UI test using Playwright, you would need to install Playwright and write a Python script that uses the Playwright library to interact with a web page. Below is an example of how you might write a test for the \"Willkommen bei disy Cadenza\" page shown in the image.\n",
      "\n",
      "First, make sure you have Playwright installed:\n",
      "\n",
      "```bash\n",
      "pip install playwright\n",
      "```\n",
      "\n",
      "Then, you can use the following Python script as a starting point for your test:\n",
      "\n",
      "```python\n",
      "import playwright\n",
      "from playwright.locators import Locator\n",
      "from playwright.wait import WebDriverWait\n",
      "\n",
      "# Initialize the browser and navigate to the page\n",
      "async def test_willkommen_page():\n",
      "    browser = playwright.chromium.launch()\n",
      "    context = await browser.new_context()\n",
      "    page = await context.new_page()\n",
      "    await page.goto('https://www.disy.cadenza.com/')\n",
      "\n",
      "    # Wait for the page to load\n",
      "    await page.wait_for_load()\n",
      "\n",
      "    # Check if the page title is correct\n",
      "    assert page.title() == 'Willkommen bei disy Cadenza'\n",
      "\n",
      "    # Check if the page contains the correct text\n",
      "    assert await page.text_content('body') == 'Willkommen bei disy Cadenza'\n",
      "\n",
      "    # Check if the page contains the correct elements\n",
      "    assert await page.is_visible('#disy-cadenza-logo')\n",
      "    assert await page.is_visible('#disy-cadenza-logo img')\n",
      "\n",
      "    # Close the browser\n",
      "    await browser.close()\n",
      "\n",
      "# Run the test\n",
      "test_willkommen_page()\n",
      "```\n",
      "\n",
      "This script will open a new browser window, navigate to the \"Willkommen bei disy Cadenza\" page, wait for the page to load, and then perform several checks to ensure that the page is functioning correctly.\n",
      "\n",
      "Please note that this is a basic example, and you may need to adjust the selectors and checks to match the specific elements and behavior of the page you are testing. \n"
     ]
    }
   ],
   "source": [
    "# One example with a image\n",
    "image_path = './screenshot/0_1.png'  # Replace with your image path\n",
    "image = Image.open(image_path)\n",
    "prompt = \"[INST] <image>\\nPlease write a python code for a UI test using playwright. [/INST]\"\n",
    "inputs = processor(prompt, image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# autoregressively complete prompt\n",
    "output = model.generate(**inputs, max_new_tokens=500)\n",
    "print(processor.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d377df9-34be-43e6-9f5e-1fea5dc3a04e",
   "metadata": {},
   "source": [
    "## 2.3 Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed0fd74e-12d4-4017-bdc1-4d2b8a883fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 100 data.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('playwright_script.db')\n",
    "cursor = conn.cursor()\n",
    "res = cursor.execute(\"SELECT * FROM tests\")\n",
    "items = res.fetchall()\n",
    "\n",
    "print( \"there are {} data.\".format(len(items)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0be5249-3c94-436a-9513-0382a1b8e1d6",
   "metadata": {},
   "source": [
    "### 2.3.1 Test with one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f25a8ff8-0600-42da-9472-67df210c910d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.1',\n",
       " '[1.1] Öffne die Arbeitsmappe \"Übersicht Messstellen\" im Ordner \"Gewässergüte\".',\n",
       " '[1.1] Expected result: Die Arbeitsmappe wird geöffnet, der Analysekontext ist nicht sichtbar.',\n",
       " '.\\\\html\\\\1_1.html',\n",
       " '.\\\\screenshot\\\\1_1.png',\n",
       " '.\\\\test_script\\\\1_1.spec.ts')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = items[0]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96b40f33-ca62-434a-8950-5effbbfcdde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: [1.1] Öffne die Arbeitsmappe \"Übersicht Messstellen\" im Ordner \"Gewässergüte\". [1.2]  Öffnen der Tabellen-Sicht \"Messstellenliste\" über die Werkzeugliste der Arbeitsmappe. [1.3] Klicke auf den 3-Punkte-Button innerhalb der Tabellen-Sicht \"Messstelleninformationen\". [1.4] Klicke auf \"Duplizieren\".\n",
      "Image format: PNG\n",
      "Image size: (1280, 720)\n",
      "Image mode: RGB\n"
     ]
    }
   ],
   "source": [
    "# Load the content\n",
    "def load_content(target)\n",
    "steps, expected_result, html_content, image, test_script = extract_content_for_database_item(target)\n",
    "\n",
    "# Display information about the image\n",
    "print(f\"Steps: {steps}\")\n",
    "print(f\"Image format: {image.format}\")\n",
    "print(f\"Image size: {image.size}\")\n",
    "print(f\"Image mode: {image.mode}\")\n",
    "\n",
    "# Get the previous state: if no previous test exists, preconditions are previous test\n",
    "precondition_html = load_html_file('./html/0_1.html')\n",
    "precondition_image = Image.open('./screenshot/0_1.png')\n",
    "precondition_test_script = open('./test_script/0_1.spec.ts', 'r', encoding='utf-8').read()\n",
    "\n",
    "def extract_previous(target):\n",
    "    previous = find_previous_test_item(target)\n",
    "    if previous != None:\n",
    "        steps_p, expected_result_p, html_content_p, image_p, test_script_p = extract_content_for_database_item(previous)\n",
    "    else:\n",
    "        steps_p = \"\" \n",
    "        expected_result_p = \"\"\n",
    "        html_content_p = precondition_html\n",
    "        image_p = precondition_image\n",
    "        test_script_p = precondition_test_script\n",
    "    return steps_p, extracted_result_p, html_content_p, image_p,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "436403d3-b01c-4d06-8111-969d0f51039a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import { test, expect } from '@playwright/test';\\nimport { writeFileSync } from 'fs';\\ntest('test', async ({ page }) => {\\n  await page.goto('http://localhost:8080/cadenza/');\\n  await page.getByRole('link', { name: 'Anmelden' }).click();\\n  await page.getByLabel('Benutzername *').click();\\n  await page.getByLabel('Benutzername *').fill('Admin');\\n  await page.getByLabel('Benutzername *').press('Tab');\\n  await page.getByPlaceholder(' ').fill('Admin');\\n  await page.getByRole('button', { name: 'Anmelden' }).click();\\n  await page.getByText('Verzeichnis Gewässergüte', { exact: true }).click();\\n  const parentElement = await page.getByText('Arbeitsmappe Übersicht Messstellen').locator('..');\\n  await parentElement.locator('.d-icon.d-icon-bold.status-icon').click(); \\n  await page.getByRole('link', { name: 'Tabelle Messstellenliste' }).click();\\n  await page.getByTestId('worksheet-view-of-type-table').hover();\\n  await page.getByTestId('worksheet-view-of-type-table').getByLabel('Mehr …').click();\\n});\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_script_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05fbbf99-e15d-4e24-8d19-6b2a719945b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". [1.4] Klicke auf \"Duplizieren\".\n",
      "No elements found for keyword '1.4'\n",
      "No elements found for keyword 'Klicke'\n",
      "Html data reduce from 1116123 to 57\n"
     ]
    }
   ],
   "source": [
    "# Handle the data\n",
    "remainder = steps.replace(steps_p, '').strip() # to only have the last step (diff between steps and steps_p => only use that step to find keywords\n",
    "print(remainder)\n",
    "html_reduce_p = reduce_html_spacy(html_content_p, remainder)\n",
    "print(f\"Html data reduce from {len(html_content)} to {len(html_reduce_p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1524a2b-0c4b-465b-9909-1981d6269514",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'steps_icl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ICL\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Prompt with previous steps\u001b[39;00m\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;124m[INST] Input = Task: Generiere ein TypeScript-Code für einen UI-Test, die Website ist erreichbar unter localhost:8080. Die HTML-Datei und das Bild stammen vom vorletzten Schritt. Die HTML-Datei ist reduziert, um nur zu zeigen, was für den letzten Schritt benötigt wird. Bitte ergänze den restlichen Code basierend auf dem gegebenen Code für den letzten Schritt., Steps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43msteps_icl\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, html: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhtml_icl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, image: <image>\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mOutput = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenerated_icl\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mInputs = Task: Generiere ein TypeScript-Code für einen UI-Test, die Website ist erreichbar unter localhost:8080. Die HTML-Datei und das Bild stammen vom vorletzten Schritt. Die HTML-Datei ist reduziert, um nur zu zeigen, was für den letzten Schritt benötigt wird. Bitte ergänze den restlichen Code basierend auf dem gegebenen Code für den letzten Schritt., Steps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, html: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhtml_reduce_p\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, image: <image>\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mOutput = \u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m[/INST]\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# prompt without prev step\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'steps_icl' is not defined"
     ]
    }
   ],
   "source": [
    "# ICL\n",
    "# Prompt with previous steps\n",
    "prompt = f'''\n",
    "[INST] Input = Task: Generiere ein TypeScript-Code für einen UI-Test, die Website ist erreichbar unter localhost:8080. Die HTML-Datei und das Bild stammen vom vorletzten Schritt. Die HTML-Datei ist reduziert, um nur zu zeigen, was für den letzten Schritt benötigt wird. Bitte ergänze den restlichen Code basierend auf dem gegebenen Code für den letzten Schritt., Steps: {steps_icl}, html: {html_icl}, image: <image>\n",
    "Output = {generated_icl}\n",
    "Inputs = Task: Generiere ein TypeScript-Code für einen UI-Test, die Website ist erreichbar unter localhost:8080. Die HTML-Datei und das Bild stammen vom vorletzten Schritt. Die HTML-Datei ist reduziert, um nur zu zeigen, was für den letzten Schritt benötigt wird. Bitte ergänze den restlichen Code basierend auf dem gegebenen Code für den letzten Schritt., Steps: {steps}, html: {html_reduce_p}, image: <image>\n",
    "Output = \n",
    "[/INST]\n",
    "'''\n",
    "\n",
    "# prompt without prev step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dedb09bc-b74a-452c-987e-9e813cd36fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''\n",
    "[INST] Bitte erstellen Sie einen Python-Code mit Playwright für die Cadenza Website, um der Beschreibung eines UI-Tests zu folgen: {steps}\n",
    "Die Cadenza Website is erreichbar in localhost:8080\n",
    "Verwenden Sie den Screenshot <image> und die HTML-Datei der Webseite als Kontext, um den Python-Code zu erstellen.\n",
    "HTML-Datei: {html_reduce}\n",
    "[/INST]\n",
    "'''\n",
    "# prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29dcd4e0-d0d0-424d-be0c-a618a01ae193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INST] Bitte erstellen Sie einen Python-Code mit Playwright für die Cadenza Website, um der Beschreibung eines UI-Tests zu folgen: [1.1] Öffne die Arbeitsmappe \"Übersicht Messstellen\" im Ordner \"Gewässergüte\".\n",
      "Die Cadenza Website is erreichbar in localhost:8080\n",
      "Verwenden Sie den Screenshot   und die HTML-Datei der Webseite als Kontext, um den Python-Code zu erstellen.\n",
      "HTML-Datei: <option data-select2-id=\"select2-data-8-6o9o\" value=\"SPECIAL_FILTER_TOKEN_WORKBOOK\">\n",
      " Arbeitsmappe\n",
      "</option>\n",
      "\n",
      "<title>\n",
      " Arbeitsmappe\n",
      "</title>\n",
      "\n",
      "<span class=\"d-nav-tree-node--text ellipsis\">\n",
      " Informationen zur Arbeitsmappe\n",
      "</span>\n",
      "\n",
      "<title>\n",
      " Arbeitsmappe\n",
      "</title>\n",
      "\n",
      "<title>\n",
      " Arbeitsmappe\n",
      "</title>\n",
      "\n",
      "<title>\n",
      " Arbeitsmappe\n",
      "</title>\n",
      "\n",
      "<span class=\"d-nav-tree-node--text ellipsis\">\n",
      " Meine Arbeitsmappen\n",
      "</span>\n",
      "\n",
      "<title>\n",
      " Arbeitsmappe\n",
      "</title>\n",
      "\n",
      "<span>\n",
      " Die Startseite von disy Cadenza ist zweigeteilt. Auf der linken Seite sehen Sie den sogenannten Navigator, über den Sie auf die angebundenen Daten zugreifen und diese visualisieren können. Auf der Startseite ist er immer geöffnet. Sobald Sie eine Arbeitsmappe oder eine Einzelsicht öffnen, wird der Navigator automatisch geschlossen.\n",
      "</span>\n",
      "\n",
      "<li>\n",
      " Arbeitsmappen mit zugehörigen Arbeitsblättern\n",
      "</li>\n",
      "\n",
      "<p>\n",
      " Im Verzeichnis Gewässergüte finden Sie sowohl Beispiele für Einzelsichten als auch für Arbeitsmappen. Englischsprachige Auswertungen sind im Verzeichnis Automobile enthalten.\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " In der Arbeitsmappe „Zugangsdaten“ sind rollenspezifische Zugangsdaten, beispielsweise für den Zugang als Analyst oder Viewer, enthalten. Außerdem finden Sie in dieser Arbeitsmappe Zugangsdaten für ein Anwendungsbeispiel mit dem Szenario Personal-Controlling.\n",
      "</p>\n",
      "\n",
      "<h2 class=\"flag\">\n",
      " 4 Arbeitsmappen\n",
      "</h2>\n",
      "\n",
      "<p>\n",
      " In disy Cadenza werden Arbeitsmappen verwendet, um einen Überblick über die Daten zu erhalten und diese gezielt zu analysieren. So können Zusammenhänge herausgearbeitet und verständlich visualisiert werden.\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " Eine Arbeitsmappe besteht aus einem oder mehreren Arbeitsblättern, in denen die Daten thematisch strukturiert aufbereitet sind.\n",
      "</p>\n",
      "\n",
      "<span>\n",
      " Klicken Sie auf dieses Symbol, um eine neue, leere Arbeitsmappe zu erstellen.\n",
      "</span>\n",
      "\n",
      "<p>\n",
      " Vorbereitete Beispiele für Arbeitsmappen finden Sie in den Verzeichnissen \"Gewässergüte\", \"Automobile\" und \"Zentrale Bereiche\".\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " Klicken Sie auf eine Arbeitsmappe, um alle enthaltenen Arbeitsblätter im Navigator anzuzeigen. Durch einen Klick auf ein Arbeitsblatt wird die Arbeitsmappe, mit dem betreffenden Arbeitsblatt darin, geöffnet.\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " In der Arbeitsmappe \"Übersicht Messtellen\" sehen Sie verschiedene Arbeitsblätter.\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " Ein Dashboard besteht aus mehreren Sichten, die gleichzeitig unterschiedliche Visualisierungen der zugrundeliegenden Daten zeigen können. Im Arbeitsblatt \"Status Quo\" der Arbeitsmappe \"Personal-Controlling\" werden die Daten beispielsweise in einer Tabelle mit farblicher Hervorhebung, einer geclusterten Karte, einem Indikator sowie in einem Kreis- und gruppierten Balkendiagramm aufbereitet dargestellt.\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " Wenn Sie die entsprechenden Rechte an der Arbeitsmappe haben, können Sie mithilfe des Datenmanagers weitere Daten hinzufügen oder im Designer weitere Einstellungen an den Daten vornehmen, wie beispielsweise die Anpassung der Aggregation oder der Darstellung.\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " Die Filter im sogenannten Analysekontext auf der linken Seite ermöglichen eine gezielte Datenauswahl in den dargestellten Sichten. Um die Daten der Arbeitsmappe auf einen für Sie relevanten Ausschnitt einzuschränken, setzen Sie die entsprechenden Filter im Analysekontext. Die Sichten im Arbeitsblatt werden automatisch aktualisiert.\n",
      "</p>\n",
      "\n",
      "<div class=\"outro-text\">\n",
      " Ausführliche Informationen zu den Arbeitsmöglichkeiten in disy Cadenza Workbooks und der Datenaufbereitung in einer Arbeitsmappe erhalten Sie in den\n",
      " <a href=\"/cadenza/help-learning/#/index/1/1\" target=\"_blank\">\n",
      "  Lernmodulen\n",
      " </a>\n",
      " .\n",
      "</div>\n",
      "\n",
      "<a class=\"d-nav-tree-node--text ellipsis\" href=\"/cadenza/public/repositories/Pc8YJDtHybIR3hDILuOJ/workbooks/AYlrNnT5PoRJJL0IZiCc\" tabindex=\"-1\">\n",
      " Übersicht Messstellen\n",
      "</a>\n",
      "\n",
      "<p>\n",
      " In der Arbeitsmappe \"Übersicht Messtellen\" sehen Sie verschiedene Arbeitsblätter.\n",
      "</p>\n",
      "\n",
      "<a class=\"d-nav-tree-node--text ellipsis\" href=\"/cadenza/public/repositories/Pc8YJDtHybIR3hDILuOJ/workbooks/AYlrNnT5PoRJJL0IZiCc\" tabindex=\"-1\">\n",
      " Übersicht Messstellen\n",
      "</a>\n",
      "\n",
      "<span class=\"d-nav-tree-node--text ellipsis\">\n",
      " Messstellenliste\n",
      "</span>\n",
      "\n",
      "<span class=\"d-nav-tree-node--text ellipsis\">\n",
      " Messstellenkarte\n",
      "</span>\n",
      "\n",
      "<span class=\"d-nav-tree-node--text ellipsis\">\n",
      " JasperReport: Druckbericht zur Anzahl der Messstellen\n",
      "</span>\n",
      "\n",
      "<a class=\"d-nav-tree-node--text ellipsis\" href=\"/cadenza/public/repositories/Pc8YJDtHybIR3hDILuOJ/workbooks/4-2I0H39LqG_JBUXi1YV\" tabindex=\"-1\">\n",
      " Messstellen-Monitoring\n",
      "</a>\n",
      "\n",
      "<span class=\"d-nav-tree-node--text ellipsis\">\n",
      " Gewässergüte\n",
      "</span>\n",
      "\n",
      "<p>\n",
      " In dieser disy Cadenza-Installation sind zu Demonstrationszwecken Daten aus den Themenbereichen Automobile, Gewässergüte und Personal-Controlling (zu finden im Verzeichnis \"Zentrale Bereiche\") enthalten. Klicken Sie auf die Info-Buttons, um Informationen zur Datenherkunft zu erhalten.\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " Im Verzeichnis Gewässergüte finden Sie sowohl Beispiele für Einzelsichten als auch für Arbeitsmappen. Englischsprachige Auswertungen sind im Verzeichnis Automobile enthalten.\n",
      "</p>\n",
      "\n",
      "<p>\n",
      " Vorbereitete Beispiele für Arbeitsmappen finden Sie in den Verzeichnissen \"Gewässergüte\", \"Automobile\" und \"Zentrale Bereiche\".\n",
      "</p>\n",
      "\n",
      "[/INST]\n",
      "```python\n",
      "import playwright\n",
      "\n",
      "# Initialize the browser\n",
      "browser = playwright.chromium.launch()\n",
      "\n",
      "# Navigate to the Cadenza website\n",
      "page = browser.new_page()\n",
      "page.goto('http://localhost:8080')\n",
      "\n",
      "# Wait for the page to load\n",
      "page.wait_for_load()\n",
      "\n",
      "# Click on the \"Übersicht Messtellen\" link\n",
      "page.click('text=Übersicht Messtellen')\n",
      "\n",
      "# Wait for the page to load after clicking the link\n",
      "page.wait_for_load()\n",
      "\n",
      "# Take a screenshot of the page\n",
      "page.screenshot('screenshot.png')\n",
      "\n",
      "# Close the browser\n",
      "browser.close()\n",
      "```\n",
      "\n",
      "HTML-Datei:\n",
      "```html\n",
      "<option data-select2-id=\"select2-data-8-6o9o\" value=\"SPECIAL_FILTER_TOKEN_WORKBOOK\">\n",
      " Arbeitsmappe\n",
      "</option>\n",
      "\n",
      "<title>\n",
      " Arbeitsmappe\n",
      "</title>\n",
      "\n",
      "<span class=\"d-nav-tree-node--text ellipsis\">\n",
      " Informationen zur Arbeitsmappe\n",
      "</span>\n",
      "\n",
      "<title>\n",
      " Arbeitsmappe\n",
      "</title>\n",
      "\n",
      "<title>\n",
      " Arbeitsmappe\n",
      "</title>\n",
      "\n",
      "<title>\n",
      " Arbeitsmappe\n",
      "</title>\n",
      "\n",
      "<span class=\"d-nav-tree-node--text ellipsis\">\n",
      " Meine Arbeitsmappen\n",
      "</span>\n",
      "\n",
      "<title>\n",
      " Arbeitsmappe\n",
      "</title>\n",
      "\n",
      "<span>\n",
      " Die Startseite von disy Cadenza ist zweigeteilt. Auf der linken Seite sehen Sie den sogenannten Navigator, über den Sie auf die angebundenen Daten zugreifen und diese visualisieren können. Auf der Startseite ist er immer geöffnet. Sobald Sie eine Arbeitsmappe oder eine Einzelsicht öffnen, wird der Navigator automatisch geschlossen.\n",
      "</span>\n",
      "\n",
      "<li>\n",
      " Arbeitsmappen mit zugehörigen Arbeitsblättern\n",
      "</li>\n",
      "\n",
      "<p>\n",
      " Im Verzeichnis Gewässergüte\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(prompt, image, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(**inputs, max_new_tokens=500)\n",
    "generated = processor.decode(output[0], skip_special_tokens=True)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3cdfb7f-ba20-42a4-a886-e4333e21382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_python_code(provided_content):\n",
    "    start_marker = \"```python\"\n",
    "    end_marker = \"```\"\n",
    "\n",
    "    start_index = provided_content.find(start_marker)\n",
    "    end_index = provided_content.find(end_marker, start_index)\n",
    "\n",
    "    if start_index != -1 and end_index != -1:\n",
    "        python_code = provided_content[start_index + len(start_marker): end_index].strip()\n",
    "        return python_code\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b591202-f623-4670-b516-31152f0162e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_python_code(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95bb8478-ee59-466d-87c4-c5ea5a9f2002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract code from generate => compare with bleu.\n",
    "# Save generated code and then in an other python script. pass the javascript to python eliminating the context or links...\n",
    "# Try to run the code localy => if run 1 if not 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
