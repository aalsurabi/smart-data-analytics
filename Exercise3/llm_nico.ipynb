{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683a90f6-4a88-40d4-8f80-2acdc1edace3",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9357a2-e2b0-4536-b3ac-11bc26d8cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (0.23.3)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: trl in /opt/conda/lib/python3.11/site-packages (0.9.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from trl) (2.2.2+cu121)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (from trl) (0.31.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (from trl) (2.19.2)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.11/site-packages (from trl) (0.8.4)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.4.0->trl) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.4.127)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate->trl) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (2.2.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets->trl) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets->trl) (1.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub transformers sentencepiece trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d4431b4-70e4-442a-9a2f-f0eea165420f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 20:13:52.058350: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-09 20:13:52.100203: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-09 20:13:52.852566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from transformers import pipeline\n",
    "from trl import setup_chat_format,SFTTrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da69a2a4-ba9a-4344-a4aa-eba87208b5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/jovyan/.cache/huggingface/token\n",
      "Login successful\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Call the login function to authenticate. You'll need to enter your credentials or token.\n",
    "token = \"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\"\n",
    "login(token=token)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e962cb-1051-4a48-8863-ce6c771faabc",
   "metadata": {},
   "source": [
    "# 1. Model trys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19338a3d-47b1-40a8-886f-d788ec581ac0",
   "metadata": {},
   "source": [
    "We tried using Meta-Llama 8B, but it was too heavy, causing the kernel to shut down. The same issue occurred with Mistal; the model is too large.\n",
    "\n",
    "Tutorial from huggingface => https://huggingface.co/docs/transformers/llm_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637b82b-7310-48b1-972e-d3c5515a3e50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1.1 Meta-LLama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b329061-c742-4dc5-9c18-ae972a660c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the model name\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "# # Load the tokenizer and model with token\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, token=token).to(device)\n",
    "\n",
    "# # Define the prompt\n",
    "# prompt = \"\"\"\n",
    "# Generate a Playwright script in TypeScript that does the following:\n",
    "# 1. Navigate to eBay Kleinanzeigen\n",
    "# 2. Accept cookies\n",
    "# 3. Accept the GDPR banner\n",
    "# 4. Search for a phone\n",
    "# 5. Take a screenshot of the search results\n",
    "# \"\"\"\n",
    "\n",
    "# # Tokenize the input\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# # Generate the script\n",
    "# outputs = model.generate(inputs.input_ids, max_length=500, num_return_sequences=1)\n",
    "\n",
    "# # Decode and print the generated text\n",
    "# generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb23d2c7-c430-4c35-a0fd-7b76f78f9bcb",
   "metadata": {},
   "source": [
    "## 1.2 GPT-Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1ea5c15-206e-413e-aa2a-c8c9b0013494",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/gpt-neo-1.3B\" # Model name for GPT-1.3\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPTNeoForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8823e729-1c6f-4f41-885b-69285f299b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  198,  8645,   378,   257, 11361,  4226,  1262,   262,  3811, 29995,\n",
      "          5888,   284,  1620, 12454,  4856,   319,  7444,    13,   220,   198,\n",
      "           464,  4226,   815,    25,   198,    16,    13, 13244, 10055,   284,\n",
      "           262,  7444, 35699,    13,   198,    17,    13, 21699, 14746,    13,\n",
      "           198,    18,    13, 11140,   329,   257,  2008,    13,   198,    19,\n",
      "            13,  7214,   257, 22032,   286,   262,  2989,  2482,    13,   198,\n",
      "           464,  2163,   815,   923,   355,  5679,    25,   198,  4299,  1332,\n",
      "            62, 11604,     7,  7700,    25,  7873,  2599,   198]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt\n",
    "prompt = \"\"\"\n",
    "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
    "The script should:\n",
    "1. Navigate to the YouTube webpage.\n",
    "2. Accept cookies.\n",
    "3. Search for a video.\n",
    "4. Take a screenshot of the search results.\n",
    "The function should start as follows:\n",
    "def test_youtube(page: Page):\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize input\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79eda90-4aaf-40de-b591-21472c6b580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "outputs = model.generate(input_ids=input_ids, \n",
    "                         pad_token_id=tokenizer.eos_token_id,  # Set pad token ID to EOS token ID\n",
    "                         attention_mask=input_ids.new_ones(input_ids.shape).to(device),  # Create attention mask\n",
    "                         max_length=500,\n",
    "                         do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95920567-1eae-4f0a-8c92-aab75968fd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
      "The script should:\n",
      "1. Navigate to the YouTube webpage.\n",
      "2. Accept cookies.\n",
      "3. Search for a video.\n",
      "4. Take a screenshot of the search results.\n",
      "The function should start as follows:\n",
      "def test_youtube(page: Page):\n",
      "    video_url = page.url\n",
      "    response = browser.get(video_url, params={'no_result' : True})\\\n",
      "    page\\\n",
      "     -> wait_for_page_to_load(video_url)\\\n",
      "     -> assert response(video_url).text\n",
      "\n",
      "I have a problem with the wait_for_page_to_load in the first line (line \\), because I always create the page before performing the test and the page isn't always available. I have tried to put it inside \\ if it was always available: but it is not.\n",
      "So, I need to wait for the video to appear, but I can't wait for the page to be ready. Can you please help me?\n",
      "\n",
      "A:\n",
      "\n",
      "The correct wait\\_for_page_to_load function to use is one you wrote (without the () on line \\).\n",
      "\n",
      "wait_for_page_to_load(page) - waits until page will be updated with status True or False. This is an absolute requirement.\n",
      "\n",
      "import requests\n",
      "from playwright.tools import wait_until, create_page as pagecreate\n",
      "wait_until(page.open)\n",
      "page.open = True\n",
      "\n",
      "However, because you don't specify if there is content waiting to be displayed or not, that will still be true regardless of the fact that a page is found\n",
      "\n",
      "A:\n",
      "\n",
      "Your code needs to wait until it can find the Youtube page at the URL you give.  If you only give it a string, it will still attempt to find it but will fail.\n",
      "For example, the following will not find your page:\n",
      "try:\n",
      "    response = browser.get(r'https://www.youtube.com/watch?v=CiOq_ZsXwEo')\n",
      "except urlopen:\n",
      "    continue\n",
      "\n",
      "Instead you have to give it a list of the pages\n"
     ]
    }
   ],
   "source": [
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27c1fd4-1bbb-4143-bdd4-d9e06ce58a0e",
   "metadata": {},
   "source": [
    "It do something, but i dont think it can the code, seems wrong. But with finetuning the model ca do better. Also a lot of text and not so much code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d2a7e-05d4-40e6-9358-b0830bfef923",
   "metadata": {},
   "source": [
    "## 1.3 CodeT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75192e08-3dc9-421d-aa1b-2305a6c739a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a769a6f4-0a2f-4a15-9cb5-6097534f3689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test yourscreenshot for you\"_test_youtube\" : function ( )] ; #YouTube app}page.onclick (Page: Page:) {0 ] }'_test_youtube' : \"\"\"Test a YouTubetest_youtube(. test_youtube }\n"
     ]
    }
   ],
   "source": [
    "# Define the input text with the updated prompt\n",
    "text = \"\"\"\n",
    "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
    "The script should:\n",
    "1. Navigate to the YouTube webpage.\n",
    "2. Accept cookies.\n",
    "3. Search for a video.\n",
    "4. Take a screenshot of the search results.\n",
    "The function should start as follows:\n",
    "def test_youtube(page: Page):\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "input_ids = inputs.input_ids\n",
    "attention_mask = inputs.attention_mask\n",
    "\n",
    "# Generate the Python script\n",
    "generated_ids = model.generate(input_ids = input_ids,\n",
    "                               attention_mask = attention_mask,\n",
    "                               max_length=500,\n",
    "                               do_sample=True)  # Adjust max_length as needed\n",
    "generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the generated Python script\n",
    "print(generated_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a5f41-435e-4899-9164-64ba243ba8f5",
   "metadata": {},
   "source": [
    "Like in gpt. To model do something, but the model it is not fitted do this, it can do better. Sometimes to model predict random stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fc8cd-317e-4ba4-ba11-3b47d3aac8d5",
   "metadata": {},
   "source": [
    "## 1.4 Mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284d1750-4cc0-47d3-b0a3-0f35ec32b513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef339deca9fb4359bbc2e391d6787d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8ebb5d7b1941b880ab42f86a3e5d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:  25%|##4       | 1.13G/4.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411bfa7996234c54ba72ec26cbd9f303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.3\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ee911-ec57-4b21-8504-8a957933581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4fe28-5df1-4d7c-a67a-507472ca1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input text with the updated prompt\n",
    "text = \"\"\"\n",
    "Generate a Python script using the Playwright library to perform UI testing on YouTube. \n",
    "The script should:\n",
    "1. Navigate to the YouTube webpage.\n",
    "2. Accept cookies.\n",
    "3. Search for a video.\n",
    "4. Take a screenshot of the search results.\n",
    "The function should start as follows:\n",
    "def test_youtube(page: Page):\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "# input_ids = inputs.input_ids\n",
    "# attention_mask = inputs.attention_mask\n",
    "\n",
    "# # Generate the Python script\n",
    "# generated_ids = model.generate(input_ids = input_ids,\n",
    "#                                attention_mask = attention_mask,\n",
    "#                                max_length=500,\n",
    "#                                do_sample=True)  # Adjust max_length as needed\n",
    "# generated_code = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# # Print the generated Python script\n",
    "# print(generated_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a68a1-7d1b-4741-9b89-d6a3914f56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
